{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of INFO5731_Assignment_Two.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SSaiTeja23/INFO5731_Spring2020/blob/master/Copy_of_Copy_of_Copy_of_INFO5731_Assignment_Two.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9",
        "colab_type": "text"
      },
      "source": [
        "# **INFO5731 Assignment Two**\n",
        "\n",
        "In this assignment, you will try to gather text data from open data source via web scraping or API. After that you need to clean the text data and syntactic analysis of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF",
        "colab_type": "text"
      },
      "source": [
        "# **Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k",
        "colab_type": "text"
      },
      "source": [
        "(40 points). Write a python program to collect text data from **either of the following sources** and save the data into a **csv file**:\n",
        "\n",
        "(1) Collect all the customer reviews of the product [2019 Dell labtop](https://www.amazon.com/Dell-Inspiron-5000-5570-Laptop/dp/B07N49F51N/ref=sr_1_11?crid=1IJ7UWF2F4GHH&keywords=dell%2Bxps%2B15&qid=1580173569&sprefix=dell%2Caps%2C181&sr=8-11&th=1) on amazon.\n",
        "\n",
        "(2) Collect the top 100 User Reviews of the film [Joker](https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv) from IMDB.\n",
        "\n",
        "(3) Collect the abstracts of the top 100 research papers by using the query [natural language processing](https://citeseerx.ist.psu.edu/search?q=natural+language+processing&submit.x=0&submit.y=0&sort=rlv&t=doc) from CiteSeerX.\n",
        "\n",
        "(4) Collect the top 100 tweets by using hashtag [\"#wuhancoronovirus\"](https://twitter.com/hashtag/wuhancoronovirus) from Twitter. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuFPKhC0m1fd",
        "colab_type": "code",
        "outputId": "c1fc581b-22f5-49f3-ab76-148205aa3038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "# Collect the top 100 tweets by using hashtag \"#wuhancoronovirus\" from Twitter.\n",
        "!pip install twitterscraper\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting twitterscraper\n",
            "  Downloading https://files.pythonhosted.org/packages/7f/0f/7cf31233d4f5616c971f6b1ae22dd73fe9a69430877f5c37a0e7b508a311/twitterscraper-1.4.0.tar.gz\n",
            "Collecting coala-utils~=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/54/00/74ec750cfc4e830f9d1cfdd4d559f3d2d4ba1b834b78d5266446db3fd1d6/coala_utils-0.5.1-py3-none-any.whl\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from twitterscraper) (0.0.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from twitterscraper) (4.2.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from twitterscraper) (2.21.0)\n",
            "Collecting billiard\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/79/a3bee8e277794f27c1cdad3a69b851d62664c419b56238435fc55b439b18/billiard-3.6.2.0-py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->twitterscraper) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->twitterscraper) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->twitterscraper) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->twitterscraper) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->twitterscraper) (2019.11.28)\n",
            "Building wheels for collected packages: twitterscraper\n",
            "  Building wheel for twitterscraper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for twitterscraper: filename=twitterscraper-1.4.0-cp36-none-any.whl size=11347 sha256=6cda8614d8c8c4d366e46c96441d58af531e5e9b60e86ee58c40ab7be79e07c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/9c/8b/7393e7bdc8abe6ce0d46c2ffae2035a1a2080a97ff0ddbdde6\n",
            "Successfully built twitterscraper\n",
            "Installing collected packages: coala-utils, billiard, twitterscraper\n",
            "Successfully installed billiard-3.6.2.0 coala-utils-0.5.1 twitterscraper-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzI5D_sjHqYm",
        "colab_type": "code",
        "outputId": "971efd65-5aa1-44ed-d9f5-f6ca77e6207b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from twitterscraper import query_tweets\n",
        "import datetime as dt\n",
        "import pandas as pd\n",
        "\n",
        "begin_date = dt.date(2020,1,10)\n",
        "end_date = dt.date(2020,2,17)\n",
        "\n",
        "limit = 200\n",
        "lang = 'english'\n",
        "\n",
        "tweets = query_tweets('#wuhancoronovirus',begindate = begin_date,enddate = end_date,limit = limit, lang = lang)\n",
        "# tweets = query_tweets('#wuhancoronovirus',limit = limit, lang = lang)\n",
        "df = pd.DataFrame(t.__dict__ for t in tweets)\n",
        "\n",
        "df.drop_duplicates(subset = \"text\",keep = False,inplace = True)\n",
        "data = df.head(100)\n",
        "# data\n",
        "# df.iloc[0]['text']\n",
        "DataFrame = data['text']\n",
        "\n",
        "# print(DataFrame)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: {'User-Agent': 'Mozilla/5.0 (compatible, MSIE 11, Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko'}\n",
            "INFO: queries: ['#wuhancoronovirus since:2020-01-10 until:2020-01-11', '#wuhancoronovirus since:2020-01-11 until:2020-01-13', '#wuhancoronovirus since:2020-01-13 until:2020-01-15', '#wuhancoronovirus since:2020-01-15 until:2020-01-17', '#wuhancoronovirus since:2020-01-17 until:2020-01-19', '#wuhancoronovirus since:2020-01-19 until:2020-01-21', '#wuhancoronovirus since:2020-01-21 until:2020-01-23', '#wuhancoronovirus since:2020-01-23 until:2020-01-25', '#wuhancoronovirus since:2020-01-25 until:2020-01-27', '#wuhancoronovirus since:2020-01-27 until:2020-01-29', '#wuhancoronovirus since:2020-01-29 until:2020-01-30', '#wuhancoronovirus since:2020-01-30 until:2020-02-01', '#wuhancoronovirus since:2020-02-01 until:2020-02-03', '#wuhancoronovirus since:2020-02-03 until:2020-02-05', '#wuhancoronovirus since:2020-02-05 until:2020-02-07', '#wuhancoronovirus since:2020-02-07 until:2020-02-09', '#wuhancoronovirus since:2020-02-09 until:2020-02-11', '#wuhancoronovirus since:2020-02-11 until:2020-02-13', '#wuhancoronovirus since:2020-02-13 until:2020-02-15', '#wuhancoronovirus since:2020-02-15 until:2020-02-17']\n",
            "INFO: Querying #wuhancoronovirus since:2020-01-11 until:2020-01-13\n",
            "INFO: Querying #wuhancoronovirus since:2020-01-10 until:2020-01-11\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Querying #wuhancoronovirus since:2020-01-17 until:2020-01-19\n",
            "INFO: Querying #wuhancoronovirus since:2020-01-15 until:2020-01-17\n",
            "INFO: Querying #wuhancoronovirus since:2020-01-13 until:2020-01-15\n",
            "INFO: Querying #wuhancoronovirus since:2020-01-21 until:2020-01-23\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Querying #wuhancoronovirus since:2020-02-11 until:2020-02-13\n",
            "INFO: Querying #wuhancoronovirus since:2020-01-19 until:2020-01-21\n",
            "INFO: Querying #wuhancoronovirus since:2020-02-05 until:2020-02-07\n",
            "INFO: Querying #wuhancoronovirus since:2020-01-27 until:2020-01-29\n",
            "INFO: Querying #wuhancoronovirus since:2020-01-30 until:2020-02-01\n",
            "INFO: Querying #wuhancoronovirus since:2020-02-09 until:2020-02-11\n",
            "INFO: Querying #wuhancoronovirus since:2020-02-13 until:2020-02-15\n",
            "INFO: Querying #wuhancoronovirus since:2020-02-01 until:2020-02-03\n",
            "INFO: Querying #wuhancoronovirus since:2020-02-15 until:2020-02-17\n",
            "INFO: Querying #wuhancoronovirus since:2020-01-23 until:2020-01-25\n",
            "INFO: Querying #wuhancoronovirus since:2020-01-25 until:2020-01-27\n",
            "INFO: Querying #wuhancoronovirus since:2020-02-07 until:2020-02-09\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-27%20until%3A2020-01-29&l=english\n",
            "INFO: Querying #wuhancoronovirus since:2020-01-29 until:2020-01-30\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-30%20until%3A2020-02-01&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-02-15%20until%3A2020-02-17&l=english\n",
            "INFO: Querying #wuhancoronovirus since:2020-02-03 until:2020-02-05\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-02-01%20until%3A2020-02-03&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-02-09%20until%3A2020-02-11&l=english\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-21%20until%3A2020-01-23&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-02-07%20until%3A2020-02-09&l=english\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-23%20until%3A2020-01-25&l=english\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-02-05%20until%3A2020-02-07&l=english\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-02-11%20until%3A2020-02-13&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-02-13%20until%3A2020-02-15&l=english\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-29%20until%3A2020-01-30&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-25%20until%3A2020-01-27&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-02-03%20until%3A2020-02-05&l=english\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Using proxy 46.4.20.90:1080\n",
            "INFO: Retrying... (Attempts left: 50)\n",
            "INFO: Retrying... (Attempts left: 50)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 189.204.242.178:8080\n",
            "INFO: Using proxy 189.204.242.178:8080\n",
            "INFO: Retrying... (Attempts left: 50)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Retrying... (Attempts left: 50)\n",
            "INFO: Using proxy 189.204.242.178:8080\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 189.204.242.178:8080\n",
            "INFO: Retrying... (Attempts left: 50)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 189.204.242.178:8080\n",
            "INFO: Retrying... (Attempts left: 50)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 189.204.242.178:8080\n",
            "INFO: Retrying... (Attempts left: 49)\n",
            "INFO: Retrying... (Attempts left: 49)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/i/search/timeline?f=tweets&vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=TWEET-1219691601695596544-1219695265474580482&q=%23wuhancoronovirus%20since%3A2020-01-21%20until%3A2020-01-23&l=english\n",
            "INFO: Using proxy 103.23.135.202:56910\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 189.204.242.178:8080\n",
            "INFO: Using proxy 103.23.135.202:56910\n",
            "INFO: Retrying... (Attempts left: 49)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 103.23.135.202:56910\n",
            "INFO: Retrying... (Attempts left: 49)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 103.23.135.202:56910\n",
            "INFO: Retrying... (Attempts left: 49)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 103.23.135.202:56910\n",
            "INFO: Retrying... (Attempts left: 49)\n",
            "INFO: Scraping tweets from https://twitter.com/i/search/timeline?f=tweets&vertical=default&include_available_features=1&include_entities=1&reset_error_state=false&src=typd&max_position=thGAVUV0VFVBaAgL_plcOb7SEWhMC0jbeYne0hEjUAFQAlAFUAFQAA&q=%23wuhancoronovirus%20since%3A2020-01-21%20until%3A2020-01-23&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 103.23.135.202:56910\n",
            "INFO: Using proxy 103.23.135.202:56910\n",
            "INFO: Retrying... (Attempts left: 48)\n",
            "INFO: Retrying... (Attempts left: 48)\n",
            "INFO: Twitter returned : 'has_more_items' \n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 103.12.161.194:59777\n",
            "INFO: Got 6 tweets for %23wuhancoronovirus%20since%3A2020-01-21%20until%3A2020-01-23.\n",
            "INFO: Using proxy 103.12.161.194:59777\n",
            "INFO: Got 6 tweets (6 new).\n",
            "INFO: Retrying... (Attempts left: 48)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 103.12.161.194:59777\n",
            "INFO: Retrying... (Attempts left: 48)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 103.12.161.194:59777\n",
            "INFO: Retrying... (Attempts left: 48)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 103.12.161.194:59777\n",
            "INFO: Got 14 tweets for %23wuhancoronovirus%20since%3A2020-02-11%20until%3A2020-02-13.\n",
            "INFO: Got 20 tweets (14 new).\n",
            "INFO: Retrying... (Attempts left: 48)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 103.12.161.194:59777\n",
            "INFO: Retrying... (Attempts left: 47)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Retrying... (Attempts left: 47)\n",
            "INFO: Got 14 tweets for %23wuhancoronovirus%20since%3A2020-02-13%20until%3A2020-02-15.\n",
            "INFO: Got 34 tweets (14 new).\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 202.154.180.53:52937\n",
            "INFO: Using proxy 202.154.180.53:52937\n",
            "INFO: Retrying... (Attempts left: 47)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 202.154.180.53:52937\n",
            "INFO: Retrying... (Attempts left: 47)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 202.154.180.53:52937\n",
            "INFO: Got 19 tweets for %23wuhancoronovirus%20since%3A2020-01-25%20until%3A2020-01-27.\n",
            "INFO: Got 53 tweets (19 new).\n",
            "INFO: Got 20 tweets for %23wuhancoronovirus%20since%3A2020-01-30%20until%3A2020-02-01.\n",
            "INFO: Got 73 tweets (20 new).\n",
            "INFO: Retrying... (Attempts left: 47)\n",
            "INFO: Got 20 tweets for %23wuhancoronovirus%20since%3A2020-01-27%20until%3A2020-01-29.\n",
            "INFO: Got 93 tweets (20 new).\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Got 19 tweets for %23wuhancoronovirus%20since%3A2020-02-05%20until%3A2020-02-07.\n",
            "INFO: Got 112 tweets (19 new).\n",
            "INFO: Using proxy 202.154.180.53:52937\n",
            "INFO: Got 20 tweets for %23wuhancoronovirus%20since%3A2020-02-01%20until%3A2020-02-03.\n",
            "INFO: Got 132 tweets (20 new).\n",
            "INFO: Got 18 tweets for %23wuhancoronovirus%20since%3A2020-01-23%20until%3A2020-01-25.\n",
            "INFO: Got 150 tweets (18 new).\n",
            "INFO: Got 18 tweets for %23wuhancoronovirus%20since%3A2020-01-29%20until%3A2020-01-30.\n",
            "INFO: Got 168 tweets (18 new).\n",
            "INFO: Got 16 tweets for %23wuhancoronovirus%20since%3A2020-02-07%20until%3A2020-02-09.\n",
            "INFO: Got 184 tweets (16 new).\n",
            "INFO: Got 18 tweets for %23wuhancoronovirus%20since%3A2020-02-03%20until%3A2020-02-05.\n",
            "INFO: Got 17 tweets for %23wuhancoronovirus%20since%3A2020-02-15%20until%3A2020-02-17.\n",
            "INFO: Got 202 tweets (18 new).\n",
            "INFO: Got 219 tweets (17 new).\n",
            "INFO: Got 15 tweets for %23wuhancoronovirus%20since%3A2020-02-09%20until%3A2020-02-11.\n",
            "INFO: Got 234 tweets (15 new).\n",
            "INFO: Retrying... (Attempts left: 47)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 202.154.180.53:52937\n",
            "INFO: Retrying... (Attempts left: 46)\n",
            "INFO: Retrying... (Attempts left: 46)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 179.124.242.34:41886\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 179.124.242.34:41886\n",
            "INFO: Retrying... (Attempts left: 46)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 179.124.242.34:41886\n",
            "INFO: Retrying... (Attempts left: 46)\n",
            "INFO: Retrying... (Attempts left: 46)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 179.124.242.34:41886\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 179.124.242.34:41886\n",
            "INFO: Retrying... (Attempts left: 46)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 179.124.242.34:41886\n",
            "INFO: Retrying... (Attempts left: 45)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 168.90.50.118:39734\n",
            "INFO: Retrying... (Attempts left: 45)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 168.90.50.118:39734\n",
            "INFO: Retrying... (Attempts left: 45)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 168.90.50.118:39734\n",
            "INFO: Retrying... (Attempts left: 45)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 168.90.50.118:39734\n",
            "INFO: Retrying... (Attempts left: 45)\n",
            "INFO: Retrying... (Attempts left: 45)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 168.90.50.118:39734\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 168.90.50.118:39734\n",
            "INFO: Retrying... (Attempts left: 44)\n",
            "INFO: Retrying... (Attempts left: 44)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 189.14.193.244:53281\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 189.14.193.244:53281\n",
            "INFO: Retrying... (Attempts left: 44)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 189.14.193.244:53281\n",
            "INFO: Retrying... (Attempts left: 44)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 189.14.193.244:53281\n",
            "INFO: Retrying... (Attempts left: 44)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 189.14.193.244:53281\n",
            "INFO: Retrying... (Attempts left: 44)\n",
            "INFO: Retrying... (Attempts left: 43)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 189.14.193.244:53281\n",
            "INFO: Using proxy 185.131.60.103:53281\n",
            "INFO: Retrying... (Attempts left: 43)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 185.131.60.103:53281\n",
            "INFO: Retrying... (Attempts left: 43)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 185.131.60.103:53281\n",
            "INFO: Retrying... (Attempts left: 43)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 185.131.60.103:53281\n",
            "INFO: Retrying... (Attempts left: 42)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 185.34.17.248:58137\n",
            "INFO: Retrying... (Attempts left: 43)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 185.131.60.103:53281\n",
            "INFO: Retrying... (Attempts left: 43)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 185.131.60.103:53281\n",
            "INFO: Retrying... (Attempts left: 42)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 185.34.17.248:58137\n",
            "INFO: Retrying... (Attempts left: 42)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 185.34.17.248:58137\n",
            "INFO: Retrying... (Attempts left: 42)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 185.34.17.248:58137\n",
            "INFO: Retrying... (Attempts left: 41)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 222.124.173.146:53281\n",
            "INFO: Retrying... (Attempts left: 42)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 185.34.17.248:58137\n",
            "INFO: Retrying... (Attempts left: 42)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 185.34.17.248:58137\n",
            "INFO: Retrying... (Attempts left: 41)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 222.124.173.146:53281\n",
            "INFO: Retrying... (Attempts left: 41)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 222.124.173.146:53281\n",
            "INFO: Retrying... (Attempts left: 41)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 222.124.173.146:53281\n",
            "INFO: Retrying... (Attempts left: 40)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 180.179.98.22:3128\n",
            "INFO: Retrying... (Attempts left: 41)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 222.124.173.146:53281\n",
            "INFO: Retrying... (Attempts left: 41)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 222.124.173.146:53281\n",
            "INFO: Retrying... (Attempts left: 40)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 180.179.98.22:3128\n",
            "INFO: Retrying... (Attempts left: 40)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Retrying... (Attempts left: 40)\n",
            "INFO: Using proxy 180.179.98.22:3128\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 180.179.98.22:3128\n",
            "INFO: Retrying... (Attempts left: 39)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 190.119.199.18:57333\n",
            "INFO: Retrying... (Attempts left: 40)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 180.179.98.22:3128\n",
            "INFO: Retrying... (Attempts left: 40)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 180.179.98.22:3128\n",
            "INFO: Retrying... (Attempts left: 39)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 190.119.199.18:57333\n",
            "INFO: Retrying... (Attempts left: 39)\n",
            "INFO: Retrying... (Attempts left: 39)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 190.119.199.18:57333\n",
            "INFO: Using proxy 190.119.199.18:57333\n",
            "INFO: Retrying... (Attempts left: 38)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Retrying... (Attempts left: 39)\n",
            "INFO: Using proxy 119.93.152.192:49889\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 190.119.199.18:57333\n",
            "INFO: Retrying... (Attempts left: 39)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 190.119.199.18:57333\n",
            "INFO: Retrying... (Attempts left: 38)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 119.93.152.192:49889\n",
            "INFO: Retrying... (Attempts left: 38)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 119.93.152.192:49889\n",
            "INFO: Retrying... (Attempts left: 38)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 119.93.152.192:49889\n",
            "INFO: Retrying... (Attempts left: 38)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 119.93.152.192:49889\n",
            "INFO: Retrying... (Attempts left: 38)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 119.93.152.192:49889\n",
            "INFO: Retrying... (Attempts left: 37)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 118.97.100.83:35220\n",
            "INFO: Retrying... (Attempts left: 37)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Retrying... (Attempts left: 37)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 118.97.100.83:35220\n",
            "INFO: Using proxy 118.97.100.83:35220\n",
            "INFO: Retrying... (Attempts left: 37)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 118.97.100.83:35220\n",
            "INFO: Retrying... (Attempts left: 37)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 118.97.100.83:35220\n",
            "INFO: Retrying... (Attempts left: 37)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 118.97.100.83:35220\n",
            "INFO: Retrying... (Attempts left: 36)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 142.93.138.69:8118\n",
            "INFO: Retrying... (Attempts left: 36)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 142.93.138.69:8118\n",
            "INFO: Retrying... (Attempts left: 36)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 142.93.138.69:8118\n",
            "INFO: Retrying... (Attempts left: 36)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 142.93.138.69:8118\n",
            "INFO: Retrying... (Attempts left: 36)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 142.93.138.69:8118\n",
            "INFO: Retrying... (Attempts left: 36)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 142.93.138.69:8118\n",
            "INFO: Retrying... (Attempts left: 35)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 178.20.137.178:43980\n",
            "INFO: Retrying... (Attempts left: 35)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 178.20.137.178:43980\n",
            "INFO: Retrying... (Attempts left: 35)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 178.20.137.178:43980\n",
            "INFO: Retrying... (Attempts left: 35)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Retrying... (Attempts left: 35)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 178.20.137.178:43980\n",
            "INFO: Using proxy 178.20.137.178:43980\n",
            "INFO: Retrying... (Attempts left: 34)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 46.229.67.198:47437\n",
            "INFO: Retrying... (Attempts left: 35)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 178.20.137.178:43980\n",
            "INFO: Retrying... (Attempts left: 34)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 46.229.67.198:47437\n",
            "INFO: Retrying... (Attempts left: 34)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 46.229.67.198:47437\n",
            "INFO: Retrying... (Attempts left: 33)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 83.13.164.202:49185\n",
            "INFO: Retrying... (Attempts left: 34)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 46.229.67.198:47437\n",
            "INFO: Retrying... (Attempts left: 34)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 46.229.67.198:47437\n",
            "INFO: Retrying... (Attempts left: 34)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 46.229.67.198:47437\n",
            "INFO: Retrying... (Attempts left: 33)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 83.13.164.202:49185\n",
            "INFO: Retrying... (Attempts left: 33)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 83.13.164.202:49185\n",
            "INFO: Retrying... (Attempts left: 32)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 200.236.221.242:36729\n",
            "INFO: Retrying... (Attempts left: 33)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 83.13.164.202:49185\n",
            "INFO: Retrying... (Attempts left: 33)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 83.13.164.202:49185\n",
            "INFO: Retrying... (Attempts left: 33)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 83.13.164.202:49185\n",
            "INFO: Retrying... (Attempts left: 32)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 200.236.221.242:36729\n",
            "INFO: Retrying... (Attempts left: 31)\n",
            "INFO: Retrying... (Attempts left: 32)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 200.236.221.242:36729\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 91.135.148.198:59384\n",
            "INFO: Retrying... (Attempts left: 32)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 200.236.221.242:36729\n",
            "INFO: Retrying... (Attempts left: 32)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 200.236.221.242:36729\n",
            "INFO: Retrying... (Attempts left: 32)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 200.236.221.242:36729\n",
            "INFO: Retrying... (Attempts left: 31)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 91.135.148.198:59384\n",
            "INFO: Retrying... (Attempts left: 30)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 118.174.220.14:43473\n",
            "INFO: Retrying... (Attempts left: 31)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 91.135.148.198:59384\n",
            "INFO: Retrying... (Attempts left: 31)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 91.135.148.198:59384\n",
            "INFO: Retrying... (Attempts left: 31)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 91.135.148.198:59384\n",
            "INFO: Retrying... (Attempts left: 30)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 118.174.220.14:43473\n",
            "INFO: Retrying... (Attempts left: 31)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 91.135.148.198:59384\n",
            "INFO: Retrying... (Attempts left: 30)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Retrying... (Attempts left: 29)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 118.174.232.237:48665\n",
            "INFO: Using proxy 118.174.220.14:43473\n",
            "INFO: Retrying... (Attempts left: 30)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 118.174.220.14:43473\n",
            "INFO: Retrying... (Attempts left: 30)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 118.174.220.14:43473\n",
            "INFO: Retrying... (Attempts left: 29)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 118.174.232.237:48665\n",
            "INFO: Retrying... (Attempts left: 30)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 118.174.220.14:43473\n",
            "INFO: Retrying... (Attempts left: 29)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 118.174.232.237:48665\n",
            "INFO: Retrying... (Attempts left: 28)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 103.250.152.30:48004\n",
            "INFO: Retrying... (Attempts left: 29)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 118.174.232.237:48665\n",
            "INFO: Retrying... (Attempts left: 29)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 118.174.232.237:48665\n",
            "INFO: Retrying... (Attempts left: 28)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 103.250.152.30:48004\n",
            "INFO: Retrying... (Attempts left: 29)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 118.174.232.237:48665\n",
            "INFO: Retrying... (Attempts left: 28)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 103.250.152.30:48004\n",
            "INFO: Retrying... (Attempts left: 28)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 103.250.152.30:48004\n",
            "INFO: Retrying... (Attempts left: 27)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 165.16.3.49:53281\n",
            "INFO: Retrying... (Attempts left: 27)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 165.16.3.49:53281\n",
            "INFO: Retrying... (Attempts left: 28)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 103.250.152.30:48004\n",
            "INFO: Retrying... (Attempts left: 28)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 103.250.152.30:48004\n",
            "INFO: Retrying... (Attempts left: 27)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 165.16.3.49:53281\n",
            "INFO: Retrying... (Attempts left: 26)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Retrying... (Attempts left: 27)\n",
            "INFO: Using proxy 42.115.88.12:46067\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 165.16.3.49:53281\n",
            "INFO: Retrying... (Attempts left: 26)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 42.115.88.12:46067\n",
            "INFO: Retrying... (Attempts left: 27)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 165.16.3.49:53281\n",
            "INFO: Retrying... (Attempts left: 27)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 165.16.3.49:53281\n",
            "INFO: Retrying... (Attempts left: 26)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 42.115.88.12:46067\n",
            "INFO: Retrying... (Attempts left: 25)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 118.174.65.170:52436\n",
            "INFO: Retrying... (Attempts left: 26)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 42.115.88.12:46067\n",
            "INFO: Retrying... (Attempts left: 25)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 118.174.65.170:52436\n",
            "INFO: Retrying... (Attempts left: 26)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 42.115.88.12:46067\n",
            "INFO: Retrying... (Attempts left: 26)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 42.115.88.12:46067\n",
            "INFO: Retrying... (Attempts left: 25)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 118.174.65.170:52436\n",
            "INFO: Retrying... (Attempts left: 24)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 78.62.214.242:60678\n",
            "INFO: Retrying... (Attempts left: 25)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 118.174.65.170:52436\n",
            "INFO: Retrying... (Attempts left: 24)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 78.62.214.242:60678\n",
            "INFO: Retrying... (Attempts left: 25)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 118.174.65.170:52436\n",
            "INFO: Retrying... (Attempts left: 25)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 118.174.65.170:52436\n",
            "INFO: Retrying... (Attempts left: 24)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 78.62.214.242:60678\n",
            "INFO: Retrying... (Attempts left: 24)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 78.62.214.242:60678\n",
            "INFO: Retrying... (Attempts left: 23)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 5.9.202.166:1080\n",
            "INFO: Retrying... (Attempts left: 24)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 78.62.214.242:60678\n",
            "INFO: Retrying... (Attempts left: 23)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 5.9.202.166:1080\n",
            "INFO: Retrying... (Attempts left: 24)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 78.62.214.242:60678\n",
            "INFO: Retrying... (Attempts left: 23)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 5.9.202.166:1080\n",
            "INFO: Retrying... (Attempts left: 22)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 202.138.247.155:8080\n",
            "INFO: Retrying... (Attempts left: 23)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 5.9.202.166:1080\n",
            "INFO: Retrying... (Attempts left: 22)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 202.138.247.155:8080\n",
            "INFO: Retrying... (Attempts left: 23)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 5.9.202.166:1080\n",
            "INFO: Retrying... (Attempts left: 23)\n",
            "INFO: Retrying... (Attempts left: 22)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 202.138.247.155:8080\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 5.9.202.166:1080\n",
            "INFO: Retrying... (Attempts left: 21)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 109.251.185.20:35935\n",
            "INFO: Retrying... (Attempts left: 22)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 202.138.247.155:8080\n",
            "INFO: Retrying... (Attempts left: 21)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 109.251.185.20:35935\n",
            "INFO: Retrying... (Attempts left: 22)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 202.138.247.155:8080\n",
            "INFO: Retrying... (Attempts left: 21)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 109.251.185.20:35935\n",
            "INFO: Retrying... (Attempts left: 22)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 202.138.247.155:8080\n",
            "INFO: Retrying... (Attempts left: 21)\n",
            "INFO: Retrying... (Attempts left: 20)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 109.199.133.161:23500\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 109.251.185.20:35935\n",
            "INFO: Retrying... (Attempts left: 20)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 109.199.133.161:23500\n",
            "INFO: Retrying... (Attempts left: 21)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 109.251.185.20:35935\n",
            "INFO: Retrying... (Attempts left: 20)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 109.199.133.161:23500\n",
            "INFO: Retrying... (Attempts left: 21)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 109.251.185.20:35935\n",
            "INFO: Retrying... (Attempts left: 19)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 178.75.21.109:36143\n",
            "INFO: Retrying... (Attempts left: 20)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 109.199.133.161:23500\n",
            "INFO: Retrying... (Attempts left: 19)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 178.75.21.109:36143\n",
            "INFO: Retrying... (Attempts left: 20)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 109.199.133.161:23500\n",
            "INFO: Retrying... (Attempts left: 19)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 178.75.21.109:36143\n",
            "INFO: Retrying... (Attempts left: 20)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 109.199.133.161:23500\n",
            "INFO: Retrying... (Attempts left: 18)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 96.87.184.101:43705\n",
            "INFO: Retrying... (Attempts left: 19)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 178.75.21.109:36143\n",
            "INFO: Retrying... (Attempts left: 19)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 178.75.21.109:36143\n",
            "INFO: Retrying... (Attempts left: 18)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 96.87.184.101:43705\n",
            "INFO: Retrying... (Attempts left: 18)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 96.87.184.101:43705\n",
            "INFO: Retrying... (Attempts left: 19)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 178.75.21.109:36143\n",
            "INFO: Retrying... (Attempts left: 17)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 177.46.148.142:3128\n",
            "INFO: Retrying... (Attempts left: 18)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 96.87.184.101:43705\n",
            "INFO: Retrying... (Attempts left: 18)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 96.87.184.101:43705\n",
            "INFO: Retrying... (Attempts left: 17)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 177.46.148.142:3128\n",
            "INFO: Retrying... (Attempts left: 18)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 96.87.184.101:43705\n",
            "INFO: Retrying... (Attempts left: 17)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 177.46.148.142:3128\n",
            "INFO: Retrying... (Attempts left: 16)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 185.59.245.199:41258\n",
            "INFO: Retrying... (Attempts left: 17)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 177.46.148.142:3128\n",
            "INFO: Retrying... (Attempts left: 17)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 177.46.148.142:3128\n",
            "INFO: Retrying... (Attempts left: 16)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 185.59.245.199:41258\n",
            "INFO: Retrying... (Attempts left: 16)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 185.59.245.199:41258\n",
            "INFO: Retrying... (Attempts left: 17)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 177.46.148.142:3128\n",
            "INFO: Retrying... (Attempts left: 15)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 118.174.46.144:45330\n",
            "INFO: Retrying... (Attempts left: 16)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 185.59.245.199:41258\n",
            "INFO: Retrying... (Attempts left: 16)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 185.59.245.199:41258\n",
            "INFO: Retrying... (Attempts left: 15)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 118.174.46.144:45330\n",
            "INFO: Retrying... (Attempts left: 15)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 118.174.46.144:45330\n",
            "INFO: Retrying... (Attempts left: 14)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Retrying... (Attempts left: 16)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 185.59.245.199:41258\n",
            "INFO: Using proxy 190.92.5.158:53281\n",
            "INFO: Retrying... (Attempts left: 15)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 118.174.46.144:45330\n",
            "INFO: Retrying... (Attempts left: 14)\n",
            "INFO: Retrying... (Attempts left: 15)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 118.174.46.144:45330\n",
            "INFO: Using proxy 190.92.5.158:53281\n",
            "INFO: Retrying... (Attempts left: 14)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 190.92.5.158:53281\n",
            "INFO: Retrying... (Attempts left: 15)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 118.174.46.144:45330\n",
            "INFO: Retrying... (Attempts left: 13)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 186.47.17.70:40437\n",
            "INFO: Retrying... (Attempts left: 14)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 190.92.5.158:53281\n",
            "INFO: Retrying... (Attempts left: 13)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 186.47.17.70:40437\n",
            "INFO: Retrying... (Attempts left: 14)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 190.92.5.158:53281\n",
            "INFO: Retrying... (Attempts left: 13)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 186.47.17.70:40437\n",
            "INFO: Retrying... (Attempts left: 14)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 190.92.5.158:53281\n",
            "INFO: Retrying... (Attempts left: 12)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 109.86.121.118:46333\n",
            "INFO: Retrying... (Attempts left: 13)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 186.47.17.70:40437\n",
            "INFO: Retrying... (Attempts left: 13)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 186.47.17.70:40437\n",
            "INFO: Retrying... (Attempts left: 13)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 186.47.17.70:40437\n",
            "INFO: Retrying... (Attempts left: 12)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 109.86.121.118:46333\n",
            "INFO: Retrying... (Attempts left: 12)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 109.86.121.118:46333\n",
            "INFO: Retrying... (Attempts left: 11)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 1.20.100.111:30095\n",
            "INFO: Retrying... (Attempts left: 12)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 109.86.121.118:46333\n",
            "INFO: Retrying... (Attempts left: 11)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 1.20.100.111:30095\n",
            "INFO: Retrying... (Attempts left: 12)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Retrying... (Attempts left: 11)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 109.86.121.118:46333\n",
            "INFO: Using proxy 1.20.100.111:30095\n",
            "INFO: Retrying... (Attempts left: 10)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 86.57.181.122:51078\n",
            "INFO: Retrying... (Attempts left: 11)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 1.20.100.111:30095\n",
            "INFO: Retrying... (Attempts left: 12)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 109.86.121.118:46333\n",
            "INFO: Retrying... (Attempts left: 10)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 86.57.181.122:51078\n",
            "INFO: Retrying... (Attempts left: 11)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 1.20.100.111:30095\n",
            "INFO: Retrying... (Attempts left: 10)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 86.57.181.122:51078\n",
            "INFO: Retrying... (Attempts left: 9)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 51.75.67.89:3128\n",
            "INFO: Retrying... (Attempts left: 10)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 86.57.181.122:51078\n",
            "INFO: Retrying... (Attempts left: 11)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 1.20.100.111:30095\n",
            "INFO: Retrying... (Attempts left: 10)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 86.57.181.122:51078\n",
            "INFO: Retrying... (Attempts left: 9)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 51.75.67.89:3128\n",
            "INFO: Retrying... (Attempts left: 9)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 51.75.67.89:3128\n",
            "INFO: Retrying... (Attempts left: 8)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 103.36.126.14:43999\n",
            "INFO: Retrying... (Attempts left: 9)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 51.75.67.89:3128\n",
            "INFO: Retrying... (Attempts left: 10)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 86.57.181.122:51078\n",
            "INFO: Retrying... (Attempts left: 8)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Retrying... (Attempts left: 9)\n",
            "INFO: Using proxy 103.36.126.14:43999\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 51.75.67.89:3128\n",
            "INFO: Retrying... (Attempts left: 8)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 103.36.126.14:43999\n",
            "INFO: Retrying... (Attempts left: 7)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 1.10.189.84:35138\n",
            "INFO: Retrying... (Attempts left: 8)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 103.36.126.14:43999\n",
            "INFO: Retrying... (Attempts left: 9)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 51.75.67.89:3128\n",
            "INFO: Retrying... (Attempts left: 7)\n",
            "INFO: Retrying... (Attempts left: 8)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 103.36.126.14:43999\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 1.10.189.84:35138\n",
            "INFO: Retrying... (Attempts left: 7)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 1.10.189.84:35138\n",
            "INFO: Retrying... (Attempts left: 6)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 101.51.106.70:45699\n",
            "INFO: Retrying... (Attempts left: 7)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 1.10.189.84:35138\n",
            "INFO: Retrying... (Attempts left: 7)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 1.10.189.84:35138\n",
            "INFO: Retrying... (Attempts left: 8)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 103.36.126.14:43999\n",
            "INFO: Retrying... (Attempts left: 6)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 101.51.106.70:45699\n",
            "INFO: Retrying... (Attempts left: 6)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 101.51.106.70:45699\n",
            "INFO: Retrying... (Attempts left: 6)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 101.51.106.70:45699\n",
            "INFO: Retrying... (Attempts left: 6)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 101.51.106.70:45699\n",
            "INFO: Retrying... (Attempts left: 5)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 1.10.188.93:34871\n",
            "INFO: Retrying... (Attempts left: 7)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 1.10.189.84:35138\n",
            "INFO: Retrying... (Attempts left: 5)\n",
            "INFO: Retrying... (Attempts left: 5)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 1.10.188.93:34871\n",
            "INFO: Using proxy 1.10.188.93:34871\n",
            "INFO: Retrying... (Attempts left: 5)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 1.10.188.93:34871\n",
            "INFO: Retrying... (Attempts left: 5)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 1.10.188.93:34871\n",
            "INFO: Retrying... (Attempts left: 4)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 202.3.72.50:56242\n",
            "INFO: Retrying... (Attempts left: 4)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 202.3.72.50:56242\n",
            "INFO: Retrying... (Attempts left: 4)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 202.3.72.50:56242\n",
            "INFO: Retrying... (Attempts left: 4)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 202.3.72.50:56242\n",
            "INFO: Retrying... (Attempts left: 4)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 202.3.72.50:56242\n",
            "INFO: Retrying... (Attempts left: 6)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 101.51.106.70:45699\n",
            "INFO: Retrying... (Attempts left: 3)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 190.122.97.138:52622\n",
            "INFO: Retrying... (Attempts left: 3)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 190.122.97.138:52622\n",
            "INFO: Retrying... (Attempts left: 3)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 190.122.97.138:52622\n",
            "INFO: Retrying... (Attempts left: 3)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Retrying... (Attempts left: 3)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 190.122.97.138:52622\n",
            "INFO: Using proxy 190.122.97.138:52622\n",
            "INFO: Retrying... (Attempts left: 5)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 1.10.188.93:34871\n",
            "INFO: Retrying... (Attempts left: 2)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 202.162.201.94:53281\n",
            "INFO: Retrying... (Attempts left: 2)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 202.162.201.94:53281\n",
            "INFO: Retrying... (Attempts left: 2)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 202.162.201.94:53281\n",
            "INFO: Retrying... (Attempts left: 2)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Using proxy 202.162.201.94:53281\n",
            "INFO: Retrying... (Attempts left: 4)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 202.3.72.50:56242\n",
            "INFO: Retrying... (Attempts left: 2)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 202.162.201.94:53281\n",
            "INFO: Retrying... (Attempts left: 1)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11&l=english\n",
            "INFO: Using proxy 103.74.70.142:35754\n",
            "INFO: Retrying... (Attempts left: 1)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13&l=english\n",
            "INFO: Using proxy 103.74.70.142:35754\n",
            "INFO: Retrying... (Attempts left: 1)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19&l=english\n",
            "INFO: Using proxy 103.74.70.142:35754\n",
            "INFO: Retrying... (Attempts left: 1)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21&l=english\n",
            "INFO: Retrying... (Attempts left: 3)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 190.122.97.138:52622\n",
            "INFO: Using proxy 103.74.70.142:35754\n",
            "INFO: Retrying... (Attempts left: 1)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17&l=english\n",
            "INFO: Using proxy 103.74.70.142:35754\n",
            "INFO: Got 0 tweets for %23wuhancoronovirus%20since%3A2020-01-10%20until%3A2020-01-11.\n",
            "INFO: Got 234 tweets (0 new).\n",
            "INFO: Got 0 tweets for %23wuhancoronovirus%20since%3A2020-01-11%20until%3A2020-01-13.\n",
            "INFO: Got 234 tweets (0 new).\n",
            "INFO: Got 0 tweets for %23wuhancoronovirus%20since%3A2020-01-17%20until%3A2020-01-19.\n",
            "INFO: Got 234 tweets (0 new).\n",
            "INFO: Retrying... (Attempts left: 2)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 202.162.201.94:53281\n",
            "INFO: Got 0 tweets for %23wuhancoronovirus%20since%3A2020-01-19%20until%3A2020-01-21.\n",
            "INFO: Got 234 tweets (0 new).\n",
            "INFO: Got 0 tweets for %23wuhancoronovirus%20since%3A2020-01-15%20until%3A2020-01-17.\n",
            "INFO: Got 234 tweets (0 new).\n",
            "INFO: Retrying... (Attempts left: 1)\n",
            "INFO: Scraping tweets from https://twitter.com/search?f=tweets&vertical=default&q=%23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15&l=english\n",
            "INFO: Using proxy 103.74.70.142:35754\n",
            "INFO: Got 0 tweets for %23wuhancoronovirus%20since%3A2020-01-13%20until%3A2020-01-15.\n",
            "INFO: Got 234 tweets (0 new).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "867MP4H_Io7u",
        "colab_type": "code",
        "outputId": "510db748-bf49-42ec-bfc9-89c2542d7989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "dt=DataFrame.reset_index(drop=True).to_frame(name='Corono_Virus_tweets')\n",
        "# display(dt)    \n",
        "\n",
        "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
        "  display(dt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Corono_Virus_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#COVID_19 = #WuhanCoronovirus \\nPlease stop us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#ChinaVirus #chinazivirus #ChinaCoronaVirus #C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Najważniejsze na świecie targi komunikacji mob...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Écrit en 1981, The Eyes of Darkness de Dean Ko...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fall in new cases raises hope in virus outbrea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Accelerate research and innovation? Mere buzz ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>中国总理访问清真寺并祈求免受#coronaravirus病毒的侵扰https://youtu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Se suspende el #MWC, el GP de China se suspend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Do you remember #Wuhan protests? Do you rememb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Let’s focus on #WuhanCoronovirus or there won’...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Our team humbly asks you to help the people in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>#WuhanCoronovirus is 9 times more contagious t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>#NeverForget\\n#NeverForgive\\n#HKPoliceTerroris...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>First hand insight into what it's like inside ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Oto jak modele komputerowe symulują przyszłe r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Not another add oil, fighting  a disease that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>20 days apart proves 14 day quarantine isn't l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Some Wuhan Evacuees Ask Why They Aren’t Being ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>I just binge watched Chernobyl. The parallels ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>CN's initial motivation for making #WuhanCoron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>#hongkong's hospital isolation wards, all u ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>#COVID19 #coronaviruschina #WuhanVirus #WuhanC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>updated Wuhan-support website, visit and post ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>https://www.google.com/amp/s/amp.theguardian.c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>This is so sad. I can’t understand why the men...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Hope it's wrong. God bless US and us. #WuhanCo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>For #ValentinesDay , #hongkongers r queuing on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>I am safe in my nuclear bunker. Thinking about...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Can't believe #ArianaGrande is trending cos of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>this is just terrifying. ##WuhanLockDown #Wuha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>BREAKING NEWS Pagi Ini Dokter Paparkan Kondisi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>#2019nCoV full genome sequences analyzed #Wuha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>81 ECMOs are being delivered to Wuhan Jinyinta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>as separation camp for patients who suspected ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>True. Our worries are meant for all as #WuhanC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>#coronarvirus\\n#CoronaOutbreak\\n#WuhanCoronovi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>#WuhanCoronovirus\\n#wuhanDonteatunclean food, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>A real time map 'bout the current situation: #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>All I’ll say is before #Vancouver and other ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>26 January update from @BBCWorld on #WuhanCoro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>@laurelchor VERY unsettling news today abt fas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Tom....this #WuhanCoronovirus is going to be a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>China says coronavirus can spread before sympt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>#WuhanCoronovirus As an Chinese international ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Ban china people from travelling to Indonesia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Le bilan du #WuhanCoronovirus s'alourdit à 80 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>#wuhanchallenge: For $20 million, would you fl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>#Wuhan #WuhanCoronovirus https://twitter.com/C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>CALL TO BAN FLIGHTS FROM CHINA TO AUSTRALIA\\nT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>#Wuhan #coronavirus #PANDEMIC BIOENGINEERED: W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Numbers update: in #China\\n1129 diagnosed\\n152...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Insightful piece on ⁦@nytopinion⁩ about how Xi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Daily update of the #coronarvirus. Please be s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>#coronarvirus #WuhanCoronavirusOutbreak #Wuhan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Coronavirus outbreak spreads globally https://...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>#WuhanCoronovirus\\n#SOSHKhttps://twitter.com/e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>@airindiain #AI1349 bringing back #indian stud...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>需要有临床执业资质的医生志愿者，为武汉市疑似或者轻症nCoV感染病人和家属，提供网上公益咨询...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>Real Sources &amp; Coverage of the Corona Virus on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>https://www.nature.com/articles/d41586-020-002...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>[好人] A sanitation workers donate wuhan 12000 元...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>Be safe everyone! #WuhanCoronovirus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>Wuhan coronavirus death toll rises to 258 in C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>Recoveries from #WuhanCoronovirus #coronarviru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>Ok, it's here.... First official patient was c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>Primer caso confirmado en España: ¿Está España...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>#Wuhancoronovırus\\nHastalıkmı ?.\\nBiyolojik si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>Panik tırmanıyor... #coronavirus #Chine #Wuhan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>YOU NEED TO READ THIS!\\n#Coronavirus #Wuhan #W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>Three more people in southern #Germany have co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>昨日武漢 今日香港\\n不斷有疑似患者暈倒在港鐵站\\n周街都係炸彈手足小心!\\nThere a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>1.29 #HK strike along with medical staff\\n#Sav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>Necesito que Nicolás haga una visita oficial a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>สู้ๆครับทุกคน #ไวรัสโคโรน่าสายพันธุ์ใหม่2019 #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>#Chinese citizen sharing a method to cure #Wuh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>#WuhanCoronovirus is not a new threat for me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>It seemed that the number of death of coronavi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>Para ficar de aviso aos malucos que ficaram in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>We're really gonna trust #California to quaran...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>Can the @CDCgov or @TravelGov please explain t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>Your job is a super high risk now.  Never work...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>The # of ppl in this thread who said masks do ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>【速報  #モーニングショー 】\\n1/29 8:41武漢在住の日本人206人を乗せたチャー...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>#AddAWordRuinABook Wuhan Animal Farm @FallonTo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>Almost all Hong Kong patients of #WuhanCoronov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>#coronavirus #WuhanCoronovirus\\nhttps://moneym...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>Esto tiene que ser coña no? .\\nEl equipo de fú...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>MR DIY hands out 3.5 million masks free to com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>The continual opening of borders like the airp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>We are living in China with lies. Wuhan ist no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>#WuhanCoronovirus #chinaoutbreak #Viruses2020 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>CORONA VIRUS: CRITICAL UPDATES from @MishelDby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>#WuhanVirus #WuhanCoronovirus #WuFlu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>Respect. Being honest is not easy in #China #W...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>Chinese doctor, Li Wenliang, Wuhan whistleblow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>RIP Dr. Li Wen-Liang!!!\\n\\n#WuhanCoronovirus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>New Video: Causes of Spread Coronavirus\\n\\nhtt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>FFS! #WuhanPneumonia #Wuhan #WuhanCoronovirus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Do we all look like a joke to you. #WuhanCoron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>calendar of coronavirus from http://en.ncov.su...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Corono_Virus_tweets\n",
              "0   #COVID_19 = #WuhanCoronovirus \\nPlease stop us...\n",
              "1   #ChinaVirus #chinazivirus #ChinaCoronaVirus #C...\n",
              "2   Najważniejsze na świecie targi komunikacji mob...\n",
              "3   Écrit en 1981, The Eyes of Darkness de Dean Ko...\n",
              "4   Fall in new cases raises hope in virus outbrea...\n",
              "5   Accelerate research and innovation? Mere buzz ...\n",
              "6   中国总理访问清真寺并祈求免受#coronaravirus病毒的侵扰https://youtu...\n",
              "7   Se suspende el #MWC, el GP de China se suspend...\n",
              "8   Do you remember #Wuhan protests? Do you rememb...\n",
              "9   Let’s focus on #WuhanCoronovirus or there won’...\n",
              "10  Our team humbly asks you to help the people in...\n",
              "11  #WuhanCoronovirus is 9 times more contagious t...\n",
              "12  #NeverForget\\n#NeverForgive\\n#HKPoliceTerroris...\n",
              "13  First hand insight into what it's like inside ...\n",
              "14  Oto jak modele komputerowe symulują przyszłe r...\n",
              "15  Not another add oil, fighting  a disease that ...\n",
              "16  20 days apart proves 14 day quarantine isn't l...\n",
              "17  Some Wuhan Evacuees Ask Why They Aren’t Being ...\n",
              "18  I just binge watched Chernobyl. The parallels ...\n",
              "19  CN's initial motivation for making #WuhanCoron...\n",
              "20  #hongkong's hospital isolation wards, all u ne...\n",
              "21  #COVID19 #coronaviruschina #WuhanVirus #WuhanC...\n",
              "22  updated Wuhan-support website, visit and post ...\n",
              "23  https://www.google.com/amp/s/amp.theguardian.c...\n",
              "24  This is so sad. I can’t understand why the men...\n",
              "25  Hope it's wrong. God bless US and us. #WuhanCo...\n",
              "26  For #ValentinesDay , #hongkongers r queuing on...\n",
              "27  I am safe in my nuclear bunker. Thinking about...\n",
              "28  Can't believe #ArianaGrande is trending cos of...\n",
              "29  this is just terrifying. ##WuhanLockDown #Wuha...\n",
              "30  BREAKING NEWS Pagi Ini Dokter Paparkan Kondisi...\n",
              "31  #2019nCoV full genome sequences analyzed #Wuha...\n",
              "32  81 ECMOs are being delivered to Wuhan Jinyinta...\n",
              "33  as separation camp for patients who suspected ...\n",
              "34  True. Our worries are meant for all as #WuhanC...\n",
              "35  #coronarvirus\\n#CoronaOutbreak\\n#WuhanCoronovi...\n",
              "36  #WuhanCoronovirus\\n#wuhanDonteatunclean food, ...\n",
              "37  A real time map 'bout the current situation: #...\n",
              "38  All I’ll say is before #Vancouver and other ma...\n",
              "39  26 January update from @BBCWorld on #WuhanCoro...\n",
              "40  @laurelchor VERY unsettling news today abt fas...\n",
              "41  Tom....this #WuhanCoronovirus is going to be a...\n",
              "42  China says coronavirus can spread before sympt...\n",
              "43  #WuhanCoronovirus As an Chinese international ...\n",
              "44  Ban china people from travelling to Indonesia ...\n",
              "45  Le bilan du #WuhanCoronovirus s'alourdit à 80 ...\n",
              "46  #wuhanchallenge: For $20 million, would you fl...\n",
              "47  #Wuhan #WuhanCoronovirus https://twitter.com/C...\n",
              "48  CALL TO BAN FLIGHTS FROM CHINA TO AUSTRALIA\\nT...\n",
              "49  #Wuhan #coronavirus #PANDEMIC BIOENGINEERED: W...\n",
              "50  Numbers update: in #China\\n1129 diagnosed\\n152...\n",
              "51  Insightful piece on ⁦@nytopinion⁩ about how Xi...\n",
              "52  Daily update of the #coronarvirus. Please be s...\n",
              "53  #coronarvirus #WuhanCoronavirusOutbreak #Wuhan...\n",
              "54  Coronavirus outbreak spreads globally https://...\n",
              "55  #WuhanCoronovirus\\n#SOSHKhttps://twitter.com/e...\n",
              "56  @airindiain #AI1349 bringing back #indian stud...\n",
              "57  需要有临床执业资质的医生志愿者，为武汉市疑似或者轻症nCoV感染病人和家属，提供网上公益咨询...\n",
              "58  Real Sources & Coverage of the Corona Virus on...\n",
              "59  https://www.nature.com/articles/d41586-020-002...\n",
              "60  [好人] A sanitation workers donate wuhan 12000 元...\n",
              "61                Be safe everyone! #WuhanCoronovirus\n",
              "62  Wuhan coronavirus death toll rises to 258 in C...\n",
              "63  Recoveries from #WuhanCoronovirus #coronarviru...\n",
              "64  Ok, it's here.... First official patient was c...\n",
              "65  Primer caso confirmado en España: ¿Está España...\n",
              "66  #Wuhancoronovırus\\nHastalıkmı ?.\\nBiyolojik si...\n",
              "67  Panik tırmanıyor... #coronavirus #Chine #Wuhan...\n",
              "68  YOU NEED TO READ THIS!\\n#Coronavirus #Wuhan #W...\n",
              "69  Three more people in southern #Germany have co...\n",
              "70  昨日武漢 今日香港\\n不斷有疑似患者暈倒在港鐵站\\n周街都係炸彈手足小心!\\nThere a...\n",
              "71  1.29 #HK strike along with medical staff\\n#Sav...\n",
              "72  Necesito que Nicolás haga una visita oficial a...\n",
              "73  สู้ๆครับทุกคน #ไวรัสโคโรน่าสายพันธุ์ใหม่2019 #...\n",
              "74  #Chinese citizen sharing a method to cure #Wuh...\n",
              "75  #WuhanCoronovirus is not a new threat for me. ...\n",
              "76  It seemed that the number of death of coronavi...\n",
              "77  Para ficar de aviso aos malucos que ficaram in...\n",
              "78  We're really gonna trust #California to quaran...\n",
              "79  Can the @CDCgov or @TravelGov please explain t...\n",
              "80  Your job is a super high risk now.  Never work...\n",
              "81  The # of ppl in this thread who said masks do ...\n",
              "82  【速報  #モーニングショー 】\\n1/29 8:41武漢在住の日本人206人を乗せたチャー...\n",
              "83  #AddAWordRuinABook Wuhan Animal Farm @FallonTo...\n",
              "84  Almost all Hong Kong patients of #WuhanCoronov...\n",
              "85  #coronavirus #WuhanCoronovirus\\nhttps://moneym...\n",
              "86  Esto tiene que ser coña no? .\\nEl equipo de fú...\n",
              "87  MR DIY hands out 3.5 million masks free to com...\n",
              "88  The continual opening of borders like the airp...\n",
              "89  We are living in China with lies. Wuhan ist no...\n",
              "90  #WuhanCoronovirus #chinaoutbreak #Viruses2020 ...\n",
              "91  CORONA VIRUS: CRITICAL UPDATES from @MishelDby...\n",
              "92               #WuhanVirus #WuhanCoronovirus #WuFlu\n",
              "93  Respect. Being honest is not easy in #China #W...\n",
              "94  Chinese doctor, Li Wenliang, Wuhan whistleblow...\n",
              "95       RIP Dr. Li Wen-Liang!!!\\n\\n#WuhanCoronovirus\n",
              "96  New Video: Causes of Spread Coronavirus\\n\\nhtt...\n",
              "97      FFS! #WuhanPneumonia #Wuhan #WuhanCoronovirus\n",
              "98  Do we all look like a joke to you. #WuhanCoron...\n",
              "99  calendar of coronavirus from http://en.ncov.su..."
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z",
        "colab_type": "text"
      },
      "source": [
        "# **Question 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw",
        "colab_type": "text"
      },
      "source": [
        "(30 points). Write a python program to **clean the text data** you collected above and save the data in a new column in the csv file. The data cleaning steps include:\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the [stopwords list](https://gist.github.com/sebleier/554280).\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming. \n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATjQNTY8buA",
        "colab_type": "code",
        "outputId": "73d40093-ed40-46e7-dda8-56c8a1535ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "dt['Corono_Virus_tweets']=dt['Corono_Virus_tweets'].str.replace(r'\\W',\" \")\n",
        "#dt['Corono_Virus_tweets']=dt['Corono_Virus_tweets'].str.replace('[\\W_]+',\"\")\n",
        "dt['Corono_Virus_tweets'] = dt['Corono_Virus_tweets'].str.replace('\\d+', '')\n",
        "\n",
        "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  \n",
        "lists = dt.values.tolist()\n",
        "\n",
        "#code to remove the chinese text from the list of tweets\n",
        "import re\n",
        "regex = re.compile('[^a-zA-Z]')\n",
        "FilteredList = []\n",
        "for i in range(len(lists)):\n",
        "  sentence = lists[i]\n",
        "  result = regex.sub(' ', sentence[0])\n",
        "  FilteredList.append(result)\n",
        "\n",
        "#code to remove the stopwords from the list of tweets\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "FilteredSentence = []\n",
        "for i in range(len(FilteredList)):\n",
        "  sentence = FilteredList[i]\n",
        "  sentence = ' '.join([word for word in sentence.split() if word not in stopwords.words(\"english\")])\n",
        "  FilteredSentence.append(sentence)\n",
        "\n",
        "# FilteredSentence\n",
        "\n",
        "#code to lowercase all text\n",
        "LowerCaseList = []\n",
        "for i in FilteredSentence:\n",
        "  LowerCaseList.append(i.lower())\n",
        "\n",
        "LowerCaseList\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['covid wuhancoronovirus please stop using abbreviations cover ccp crime https twitter com liuyun status',\n",
              " 'chinavirus chinazivirus chinacoronavirus chinapneumonia wuhancoronovirus wuhansars wuhanviruspic twitter com fxnbfbgh',\n",
              " 'najwa niejsze na wiecie targi komunikacji mobilnej mwc w barcelonie zostan odwo ane w tym roku ze wzgl du na ryzyko koronawirusa w obawie przed wirusem wiele znanych firm odwo ju sw j udzia w wiatowym kongresie mobilnym https grossstadthexe wuhancoronovirus',\n",
              " 'crit en the eyes darkness de dean koontz suit un virus appel wuhan velopp dans les laboratoires militaires de wuhan en chine wuhancoronovirus https twitter com reallygraceful status',\n",
              " 'fall new cases raises hope virus outbreak china https apnews com cdfdceabdeaa wuhancoronovirus',\n",
              " 'accelerate research innovation mere buzz words sound impressive masses you influence chinese government and everyone knows shameonyou wuhancoronov rus china',\n",
              " 'coronaravirus https youtu zulwkdbby coronaravirus wuhancoronovirus chinawuhan covi covid valentines wuhancoronovirusmalaysia wuhanvirus coronavirus',\n",
              " 'se suspende el mwc el gp de china se suspende que nos dicen del coronavirus covid wuhancoronovirus',\n",
              " 'do remember wuhan protests do remember ccp ignored citizens demands https www google com amp www bbc com news amp blogs china blog https youtu zvfavspu and wuhancoronovirus breaks ccp still ignored citizens demands human rights democracy necessary everyone',\n",
              " 'let focus wuhancoronovirus country secure election',\n",
              " 'our team humbly asks help people china lacking masks protective gear fight wuhan coronavirus please kindly make donation thru official website contact us details https buff ly ukrn wuhancoronovirus protectthechildrenpic twitter com wykbvvb',\n",
              " 'wuhancoronovirus times contagious sars however carrie lame duck govt chosen sit sidelines nothing sustain sufficient mask supplies all measures r match w sars no wonder bloomberg said hk govt showing symptoms failed state',\n",
              " 'neverforget neverforgive hkpoliceterrorism hkpolicestate standwithhongkong hongkong china terrorists antichinazi wuhancoronovirus https twitter com aaronmcn status',\n",
              " 'first hand insight like inside coronavirus field hospital xhnews reporter xu zeyu coronavirus wuhanjiayou hospital outbreak wuhancoronov rus chinadaily chinadailynews https www facebook com watch v',\n",
              " 'oto jak modele komputerowe symuluj przysz e rozprzestrzenianie si nowego koronawirusa wuhancoronovirus here how computer models simulate future spread new coronavirus http translate google com translate hl pl sl auto tl pl u https a f fwww scientificamerican com farticle fheres computer models simulate future spread new coronavirus f famp https www scientificamerican com article heres computer models simulate future spread new coronavirus amp',\n",
              " 'not another add oil fighting disease spread like fire adding oil appropriate try give blessing the act wuhan rising recovery know classic knowledge wuhancoronov rus chinesepic twitter com stjlsolbc',\n",
              " 'days apart proves day quarantine long enough time wuhancoronovirus covid ccp coronavirus wuhanvirus cdcemergency who whitehouse foxnews cnn',\n",
              " 'some wuhan evacuees ask why they aren being tested coronavirus https dnyuz com wuhan evacuees ask arent tested coronavirus coronaviruswuhan coronavirususa wuhan wuhancoronovirus dnyuzcom',\n",
              " 'i binge watched chernobyl the parallels amazing a communist regime putting face saving good party anything else killing process chilling coronavirusus coronavirusdeaths coronaviruswuhan coronavirusuk wuhancoronovirus',\n",
              " 'cn initial motivation making wuhancoronovirus kill ppl tw bcoz want use military force however ccp management ability always poor caused virus leaking wuhanplab harming ppl coronavirustruth',\n",
              " 'hongkong hospital isolation wards u need plastic sheeting world class city right soshk carrielam useless wuhancoronovirus coronavirusoutbreakpic twitter com kvrdmsrjt',\n",
              " 'covid coronaviruschina wuhanvirus wuhancoronovirus https twitter com michaelcbender status',\n",
              " 'updated wuhan support website visit post ur voice wuhanvirus wuhancoronovirus https cultech biz message wuhan',\n",
              " 'https www google com amp amp theguardian com world feb london coronavirus patient turned hospital uber taxi it difficult thing world make ppl obey rules china coronaviruslondon wuhancoronovirus pic twitter com cwnkhdqbw',\n",
              " 'this sad i understand men black profile gear wuhancoronovirus https twitter com byron wan status',\n",
              " 'hope wrong god bless us us wuhancoronovirus wuhanvirus https twitter com drericding status',\n",
              " 'for valentinesday hongkongers r queuing online person face masks at given time r mil ppl ahead u waitlist pharmacy masks carrielam said gov still find wuhancoronovirus hongkong gov useless pic twitter com xgbzswo',\n",
              " 'i safe nuclear bunker thinking kicking francis coppola stop talking making sequel one from the heart shut francis valentinesday wuhancoronavirus wuhancoronovirus coronoavirusoutbreakhttps twitter com wsj status',\n",
              " 'can believe arianagrande trending cos dress grammy asian continent world people dying wuhancoronovirus',\n",
              " 'terrifying wuhanlockdown wuhancoronovirus wuhanquarantine wuhanoutbreak coronaoutbreak coronavirusoutbreak wuhanpnemoniahttps twitter com bnodesk status',\n",
              " 'breaking news pagi ini dokter paparkan kondisi pasien di jambi yang diduga kena virus corona tribunjambi viruscorona coronavirus jambi wuhancoronovirus wuhanpneumonia coronaoutbreak https jambi tribunnews com breaking news pagi ini dokter paparkan kondisi pasien di jambi yang diduga kena virus corona lewat tribunjambiku',\n",
              " 'ncov full genome sequences analyzed wuhancoronovirus https twitter com who status',\n",
              " 'ecmos delivered wuhan jinyintan hospital to put perspective top shanghai hospital zhongshan on yo male patient wuhan rescued ecmo https bit ly gqqpmi wuhan ncov wuhancoronovirus pic twitter com guazcknba',\n",
              " 'separation camp patients suspected infection wuhancoronovirus',\n",
              " 'true our worries meant wuhancoronovirus spreading rapid mode',\n",
              " 'coronarvirus coronaoutbreak wuhancoronovirus coronaviruschinahttps www fatimacoeg site virus corona buat kota ini seperti kota html',\n",
              " 'wuhancoronovirus wuhandonteatunclean food read bible chapter leviticuspic twitter com qniojugiz',\n",
              " 'a real time map bout current situation coronaoutbreak https gisanddata maps arcgis com apps opsdashboard index html bdafdbeecf coronarvirus coronaoutbreak wuhancoronovirus',\n",
              " 'all i say vancouver major cities canada resemble wuhan start provisioning now coronarvirus wuhancoronovirus itsalreadyhere',\n",
              " 'january update bbcworld wuhancoronovirus coronavirusoutbreakhttps www youtube com watch v jawpcypfqc',\n",
              " 'laurelchor very unsettling news today abt fast transmissibility wuhancoronovirus yr insightful thought abt makes think many well known ppl usa europe publicly asking yr question what take change behavior https twitter com laurelchor status',\n",
              " 'tom wuhancoronovirus going shit storm',\n",
              " 'china says coronavirus spread symptoms show death toll grows th us case confirmed coronarvirus wuhancoronovirus',\n",
              " 'wuhancoronovirus as chinese international student us i extremely worried family they asked stay us spring break told one friend may infected i wish normal fever thankfully family healthy yet',\n",
              " 'ban china people travelling indonesia right wuhancoronovirus coronarvirus wuhan',\n",
              " 'le bilan du wuhancoronovirus alourdit morts https twitter com williamyang status',\n",
              " 'wuhanchallenge for million would fly wuhanchina take train cities wash hands point used bathroom several times eat chicken wings hands sleep f room sheet wuhancoronovirus',\n",
              " 'wuhan wuhancoronovirus https twitter com cat status',\n",
              " 'call to ban flights from china to australia the pm pressure stop flights australia china qantas reportedly prepares send crew evacuate australians wuhancoronovirus wuhanchinapic twitter com hwovqdjjuk',\n",
              " 'wuhan coronavirus pandemic bioengineered who behind china wuhancoronovirus coronaviruswho http stateofthenation co p',\n",
              " 'numbers update china diagnosed suspected deaths cured wuhan wuhancoronovirus wuhanpneumonia coronavirus',\n",
              " 'insightful piece nytopinion xi authoritarian governance model enables global outbreak wuhancoronovirus https www nytimes com opinion coronavirus china government html',\n",
              " 'daily update coronarvirus please safe people maintain good personal hygiene stay home sick stats wuhancoronovirus pic twitter com gtowhdd',\n",
              " 'coronarvirus wuhancoronavirusoutbreak wuhancoronovirus wuhanhttps twitter com plumwdhse status',\n",
              " 'coronavirus outbreak spreads globally https cnn rftssk corona coronaviruswho wuhancoronavirusoutbreak wuhancoronovirus wuhanpneumonia wuhanchina china wuhanlockdown wuhanoutbreak fridaythoughts',\n",
              " 'wuhancoronovirus soshkhttps twitter com ezracheungtoto status',\n",
              " 'airindiain ai bringing back indian students wuhanchina entered india airspace salute brave crew air india hardeepspuri coronarvirus wuhancoronovirus coronaviruswho https twitter com robinjindia status pic twitter com rirqlmga',\n",
              " 'ncov coronarvirus wuhancoronovirus pic twitter com csmwlovz',\n",
              " 'real sources coverage corona virus page follow updates wuhancoronovirus coronavirus ncov wuhan hubei breakinghttps twitter com gibsfree status',\n",
              " 'https www nature com articles wohc wuhancoronovirus',\n",
              " 'a sanitation workers donate wuhan telegram wuhancoronovirus https youtu b ymnfxdtta',\n",
              " 'be safe everyone wuhancoronovirus',\n",
              " 'wuhan coronavirus death toll rises china new fatalities cna wuhancoronovirus wuhanoutbreak wuhanflu wuhanflu ncov coronoavirus wuhanhttps www channelnewsasia com news asia wuhan virus death toll rises china cases',\n",
              " 'recoveries wuhancoronovirus coronarvirus outpace deaths first timepic twitter com bwzkhhpen',\n",
              " 'ok first official patient confirmed th december st december link wuhan sea market coronarvirus wuhancoronovirus ncov coronavirusoutbreak coronaviruschinahttps www sciencemag org news wuhan seafood market may source novel virus spreading globally',\n",
              " 'primer caso confirmado en espa est espa preparada para el coronavirus m informaci n https raroraroraro github io prle pandemia coronavirus wuhancoronovirus wuhan coronavirusespanapic twitter com gthdzgxm',\n",
              " 'wuhancoronov rus hastal km biyolojik silahm who opinion coronavirus leaked weapon https www livemint com opinion quick edit coronavirus leaked weapon html',\n",
              " 'panik rman yor coronavirus chine wuhancoronovirus https twitter com slmhktn status',\n",
              " 'you need to read this coronavirus wuhan wuhancoronovirus https twitter com thesharpedge status',\n",
              " 'three people southern germany contracted coronavirus employees company man became first person germany become infected virus bavarian health ministry said tuesday wuhancoronovirus coronaviruspic twitter com wjccppfsv',\n",
              " 'there people suspected wuhancoronovirus fainting suddenly metro station hk it terrible already around us you never know someone fall next pic twitter com bjozxnblee',\n",
              " 'hk strike along medical staff savelife savehongkong wuhancoronovirus coronavirusoutbreak wuhanoutbreak soshk ccp china terrorist antichinazi antiauthoritanismpic twitter com ngiaxfay',\n",
              " 'necesito que nicol haga una visita oficial wuhancoronovirus hecho la vistima buscando convenios eso',\n",
              " 'wuhancoronovirus https twitter com goodlast hope status',\n",
              " 'chinese citizen sharing method cure wuhancoronovirus bring garlic water boil drink cups day this ordinary fakenews spreading around social media china https twitter com kui yang status',\n",
              " 'wuhancoronovirus new threat it extension simmering panic i experience every winter leaving house preparing traverse bio toxic environment',\n",
              " 'it seemed number death coronavirus patients china changed regularly wuhancoronovirus',\n",
              " 'para ficar de aviso aos malucos que ficaram inventando n meros de infectados e mortos ela n tem freio autom tico n ter que ser contida descartem essa lorota de que se deixar ela perde coronavirus coronarvirues coronaoutbreak brasil wuhancoronovirus pic twitter com deltejabh',\n",
              " 'we really gonna trust california quarantine americans flying america possibly w coronavirus ca even keep mexicans china wuhan wuhancoronovirus wuhanvirus',\n",
              " 'can cdcgov travelgov please explain usa accepting planes willingly ground zero location rapidly spreading coronavirus killed several people hospitalized many wuhanoutbreak wuhancoronovirus wuhanchinahttps twitter com livecrisisnews status',\n",
              " 'your job super high risk never work without masks goggle rmb virus could noticeable symptoms even fever wuhancoronovirus',\n",
              " 'the ppl thread said masks work ridiculous yes masks the best way stop u catching wuhancoronovirus washing hands helps https twitter com apriloa status',\n",
              " 'wuhancoronovirus pic twitter com foaspocwr',\n",
              " 'addawordruinabook wuhan animal farm fallontonight wuhancoronovirus pic twitter com ufmdssro',\n",
              " 'almost hong kong patients wuhancoronovirus come mainland they hongkongers they people come infect us there reasons nurses risk life serve china https twitter com cnni status',\n",
              " 'coronavirus wuhancoronovirus https moneymaven io mishtalk economics hundreds virus carrying planes headed us london paris vancouver ejnxiubmhk cunpwjclna',\n",
              " 'esto tiene que ser co el equipo de f tbol de wuhancoronovirus llegar ana m laga hacer la pretemporada https www elmundo es deportes futbol edcfccafbcf html',\n",
              " 'mr diy hands million masks free combat virus https www thestar com news nation mr diy hands million masks free combat virus xjyfqgv twitter thank mr diy salute wuhancoronovirus wuhanoutbreak wuhan',\n",
              " 'the continual opening borders like airport means influx probable wuhancoronovirus carriers hk this put hkers matter political spectrum high risk the medical sector facing unbearable pressure collapses hkers suffer',\n",
              " 'we living china lies wuhan ist like hell more people dying liwenliang coronavirus lies help sos wuhan wuhancoronovirus https twitter com wangzhian status',\n",
              " 'wuhancoronovirus chinaoutbreak viruses facts pic twitter com mlnsriocp',\n",
              " 'corona virus critical updates misheldbytes deceptionbytes qanons qarmy panicinchina wearethenewsnow qnews coronavirus q wwgwga wuhanoutbreak coronavirusoutbreak quarantine wuhancoronovirus seektruthcuzdeceptionbytes https youtu xobeazfivg via youtube',\n",
              " 'wuhanvirus wuhancoronovirus wuflu',\n",
              " 'respect being honest easy china wuhancoronovirus china soshk',\n",
              " 'chinese doctor li wenliang wuhan whistleblower ill coronavirus february zacharykhubbard gematria broadcast coronavirus https youtu zsoq vg wuhanoutbreak coronavirustruth wuhancoronovirus chinavirus coronaviruschallenge chinawuhan',\n",
              " 'rip dr li wen liang wuhancoronovirus',\n",
              " 'new video causes spread coronavirus https youtu zngvaggqdw coronavirus corona virus health china chinavirus wuhan wuhancoronovirus pic twitter com caabyjts',\n",
              " 'ffs wuhanpneumonia wuhan wuhancoronovirus',\n",
              " 'do look like joke wuhancoronovirus https twitter com vanessa zhanguk status',\n",
              " 'calendar coronavirus http en ncov su see trash coronavirus wuhancoronovirus ncov ncov wuhanpnemoniapic twitter com zvygcomc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeT07yj1RZYx",
        "colab_type": "code",
        "outputId": "53b283f6-53a7-4283-8a2d-1aad158c1b96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "a=[]\n",
        "StemList = []\n",
        "StemWords=[]\n",
        "for i in LowerCaseList:\n",
        "  StemWords.append(\" \".join([porter.stem(j) for j in i.split()]))\n",
        "StemWords\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stemming\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/eb/fd53fb51b83a4e3b8e98cfec2fa9e4b99401fce5177ec346e4a5c61df71e/stemming-1.0.1.tar.gz\n",
            "Building wheels for collected packages: stemming\n",
            "  Building wheel for stemming (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stemming: filename=stemming-1.0.1-cp36-none-any.whl size=11139 sha256=202f4d7697c331982c9567003c1db6b75ab11700f39ddf2888d239b97919137d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/05/2e/2ddeb64d4464b854b48323f9676528c17560da7d153db7b0e2\n",
            "Successfully built stemming\n",
            "Installing collected packages: stemming\n",
            "Successfully installed stemming-1.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['covid wuhancoronoviru pleas stop use abbrevi cover ccp crime http twitter com liuyun statu',\n",
              " 'chinaviru chinaziviru chinacoronaviru chinapneumonia wuhancoronoviru wuhansar wuhanvirusp twitter com fxnbfbgh',\n",
              " 'najwa niejsz na wieci targi komunikacji mobilnej mwc w barceloni zostan odwo ane w tym roku ze wzgl du na ryzyko koronawirusa w obawi przed wirusem wiel znanych firm odwo ju sw j udzia w wiatowym kongresi mobilnym http grossstadthex wuhancoronoviru',\n",
              " 'crit en the eye dark de dean koontz suit un viru appel wuhan velopp dan le laboratoir militair de wuhan en chine wuhancoronoviru http twitter com reallygrac statu',\n",
              " 'fall new case rais hope viru outbreak china http apnew com cdfdceabdeaa wuhancoronoviru',\n",
              " 'acceler research innov mere buzz word sound impress mass you influenc chines govern and everyon know shameony wuhancoronov ru china',\n",
              " 'coronaraviru http youtu zulwkdbbi coronaraviru wuhancoronoviru chinawuhan covi covid valentin wuhancoronovirusmalaysia wuhanviru coronaviru',\n",
              " 'se suspend el mwc el gp de china se suspend que no dicen del coronaviru covid wuhancoronoviru',\n",
              " 'do rememb wuhan protest do rememb ccp ignor citizen demand http www googl com amp www bbc com news amp blog china blog http youtu zvfavspu and wuhancoronoviru break ccp still ignor citizen demand human right democraci necessari everyon',\n",
              " 'let focu wuhancoronoviru countri secur elect',\n",
              " 'our team humbl ask help peopl china lack mask protect gear fight wuhan coronaviru pleas kindli make donat thru offici websit contact us detail http buff ly ukrn wuhancoronoviru protectthechildrenp twitter com wykbvvb',\n",
              " 'wuhancoronoviru time contagi sar howev carri lame duck govt chosen sit sidelin noth sustain suffici mask suppli all measur r match w sar no wonder bloomberg said hk govt show symptom fail state',\n",
              " 'neverforget neverforg hkpoliceterror hkpolicest standwithhongkong hongkong china terrorist antichinazi wuhancoronoviru http twitter com aaronmcn statu',\n",
              " 'first hand insight like insid coronaviru field hospit xhnew report xu zeyu coronaviru wuhanjiay hospit outbreak wuhancoronov ru chinadaili chinadailynew http www facebook com watch v',\n",
              " 'oto jak model komputerow symuluj przysz e rozprzestrzeniani si nowego koronawirusa wuhancoronoviru here how comput model simul futur spread new coronaviru http translat googl com translat hl pl sl auto tl pl u http a f fwww scientificamerican com farticl fhere comput model simul futur spread new coronaviru f famp http www scientificamerican com articl here comput model simul futur spread new coronaviru amp',\n",
              " 'not anoth add oil fight diseas spread like fire ad oil appropri tri give bless the act wuhan rise recoveri know classic knowledg wuhancoronov ru chinesep twitter com stjlsolbc',\n",
              " 'day apart prove day quarantin long enough time wuhancoronoviru covid ccp coronaviru wuhanviru cdcemerg who whitehous foxnew cnn',\n",
              " 'some wuhan evacue ask whi they aren be test coronaviru http dnyuz com wuhan evacue ask arent test coronaviru coronaviruswuhan coronavirususa wuhan wuhancoronoviru dnyuzcom',\n",
              " 'i bing watch chernobyl the parallel amaz a communist regim put face save good parti anyth els kill process chill coronavirusu coronavirusdeath coronaviruswuhan coronavirusuk wuhancoronoviru',\n",
              " 'cn initi motiv make wuhancoronoviru kill ppl tw bcoz want use militari forc howev ccp manag abil alway poor caus viru leak wuhanplab harm ppl coronavirustruth',\n",
              " 'hongkong hospit isol ward u need plastic sheet world class citi right soshk carrielam useless wuhancoronoviru coronavirusoutbreakp twitter com kvrdmsrjt',\n",
              " 'covid coronaviruschina wuhanviru wuhancoronoviru http twitter com michaelcbend statu',\n",
              " 'updat wuhan support websit visit post ur voic wuhanviru wuhancoronoviru http cultech biz messag wuhan',\n",
              " 'http www googl com amp amp theguardian com world feb london coronaviru patient turn hospit uber taxi it difficult thing world make ppl obey rule china coronaviruslondon wuhancoronoviru pic twitter com cwnkhdqbw',\n",
              " 'thi sad i understand men black profil gear wuhancoronoviru http twitter com byron wan statu',\n",
              " 'hope wrong god bless us us wuhancoronoviru wuhanviru http twitter com drericd statu',\n",
              " 'for valentinesday hongkong r queu onlin person face mask at given time r mil ppl ahead u waitlist pharmaci mask carrielam said gov still find wuhancoronoviru hongkong gov useless pic twitter com xgbzswo',\n",
              " 'i safe nuclear bunker think kick franci coppola stop talk make sequel one from the heart shut franci valentinesday wuhancoronaviru wuhancoronoviru coronoavirusoutbreakhttp twitter com wsj statu',\n",
              " 'can believ arianagrand trend co dress grammi asian contin world peopl die wuhancoronoviru',\n",
              " 'terrifi wuhanlockdown wuhancoronoviru wuhanquarantin wuhanoutbreak coronaoutbreak coronavirusoutbreak wuhanpnemoniahttp twitter com bnodesk statu',\n",
              " 'break news pagi ini dokter paparkan kondisi pasien di jambi yang diduga kena viru corona tribunjambi viruscorona coronaviru jambi wuhancoronoviru wuhanpneumonia coronaoutbreak http jambi tribunnew com break news pagi ini dokter paparkan kondisi pasien di jambi yang diduga kena viru corona lewat tribunjambiku',\n",
              " 'ncov full genom sequenc analyz wuhancoronoviru http twitter com who statu',\n",
              " 'ecmo deliv wuhan jinyintan hospit to put perspect top shanghai hospit zhongshan on yo male patient wuhan rescu ecmo http bit ly gqqpmi wuhan ncov wuhancoronoviru pic twitter com guazcknba',\n",
              " 'separ camp patient suspect infect wuhancoronoviru',\n",
              " 'true our worri meant wuhancoronoviru spread rapid mode',\n",
              " 'coronarviru coronaoutbreak wuhancoronoviru coronaviruschinahttp www fatimacoeg site viru corona buat kota ini seperti kota html',\n",
              " 'wuhancoronoviru wuhandonteatunclean food read bibl chapter leviticusp twitter com qniojugiz',\n",
              " 'a real time map bout current situat coronaoutbreak http gisanddata map arcgi com app opsdashboard index html bdafdbeecf coronarviru coronaoutbreak wuhancoronoviru',\n",
              " 'all i say vancouv major citi canada resembl wuhan start provis now coronarviru wuhancoronoviru itsalreadyher',\n",
              " 'januari updat bbcworld wuhancoronoviru coronavirusoutbreakhttp www youtub com watch v jawpcypfqc',\n",
              " 'laurelchor veri unsettl news today abt fast transmiss wuhancoronoviru yr insight thought abt make think mani well known ppl usa europ publicli ask yr question what take chang behavior http twitter com laurelchor statu',\n",
              " 'tom wuhancoronoviru go shit storm',\n",
              " 'china say coronaviru spread symptom show death toll grow th us case confirm coronarviru wuhancoronoviru',\n",
              " 'wuhancoronoviru as chines intern student us i extrem worri famili they ask stay us spring break told one friend may infect i wish normal fever thank famili healthi yet',\n",
              " 'ban china peopl travel indonesia right wuhancoronoviru coronarviru wuhan',\n",
              " 'le bilan du wuhancoronoviru alourdit mort http twitter com williamyang statu',\n",
              " 'wuhanchalleng for million would fli wuhanchina take train citi wash hand point use bathroom sever time eat chicken wing hand sleep f room sheet wuhancoronoviru',\n",
              " 'wuhan wuhancoronoviru http twitter com cat statu',\n",
              " 'call to ban flight from china to australia the pm pressur stop flight australia china qanta reportedli prepar send crew evacu australian wuhancoronoviru wuhanchinap twitter com hwovqdjjuk',\n",
              " 'wuhan coronaviru pandem bioengin who behind china wuhancoronoviru coronaviruswho http stateofthen co p',\n",
              " 'number updat china diagnos suspect death cure wuhan wuhancoronoviru wuhanpneumonia coronaviru',\n",
              " 'insight piec nytopinion xi authoritarian govern model enabl global outbreak wuhancoronoviru http www nytim com opinion coronaviru china govern html',\n",
              " 'daili updat coronarviru pleas safe peopl maintain good person hygien stay home sick stat wuhancoronoviru pic twitter com gtowhdd',\n",
              " 'coronarviru wuhancoronavirusoutbreak wuhancoronoviru wuhanhttp twitter com plumwdhs statu',\n",
              " 'coronaviru outbreak spread global http cnn rftssk corona coronaviruswho wuhancoronavirusoutbreak wuhancoronoviru wuhanpneumonia wuhanchina china wuhanlockdown wuhanoutbreak fridaythought',\n",
              " 'wuhancoronoviru soshkhttp twitter com ezracheungtoto statu',\n",
              " 'airindiain ai bring back indian student wuhanchina enter india airspac salut brave crew air india hardeepspuri coronarviru wuhancoronoviru coronaviruswho http twitter com robinjindia statu pic twitter com rirqlmga',\n",
              " 'ncov coronarviru wuhancoronoviru pic twitter com csmwlovz',\n",
              " 'real sourc coverag corona viru page follow updat wuhancoronoviru coronaviru ncov wuhan hubei breakinghttp twitter com gibsfre statu',\n",
              " 'http www natur com articl wohc wuhancoronoviru',\n",
              " 'a sanit worker donat wuhan telegram wuhancoronoviru http youtu b ymnfxdtta',\n",
              " 'be safe everyon wuhancoronoviru',\n",
              " 'wuhan coronaviru death toll rise china new fatal cna wuhancoronoviru wuhanoutbreak wuhanflu wuhanflu ncov coronoaviru wuhanhttp www channelnewsasia com news asia wuhan viru death toll rise china case',\n",
              " 'recoveri wuhancoronoviru coronarviru outpac death first timep twitter com bwzkhhpen',\n",
              " 'ok first offici patient confirm th decemb st decemb link wuhan sea market coronarviru wuhancoronoviru ncov coronavirusoutbreak coronaviruschinahttp www sciencemag org news wuhan seafood market may sourc novel viru spread global',\n",
              " 'primer caso confirmado en espa est espa preparada para el coronaviru m informaci n http raroraroraro github io prle pandemia coronaviru wuhancoronoviru wuhan coronavirusespanap twitter com gthdzgxm',\n",
              " 'wuhancoronov ru hastal km biyolojik silahm who opinion coronaviru leak weapon http www livemint com opinion quick edit coronaviru leak weapon html',\n",
              " 'panik rman yor coronaviru chine wuhancoronoviru http twitter com slmhktn statu',\n",
              " 'you need to read thi coronaviru wuhan wuhancoronoviru http twitter com thesharpedg statu',\n",
              " 'three peopl southern germani contract coronaviru employe compani man becam first person germani becom infect viru bavarian health ministri said tuesday wuhancoronoviru coronavirusp twitter com wjccppfsv',\n",
              " 'there peopl suspect wuhancoronoviru faint suddenli metro station hk it terribl alreadi around us you never know someon fall next pic twitter com bjozxnble',\n",
              " 'hk strike along medic staff savelif savehongkong wuhancoronoviru coronavirusoutbreak wuhanoutbreak soshk ccp china terrorist antichinazi antiauthoritanismp twitter com ngiaxfay',\n",
              " 'necesito que nicol haga una visita ofici wuhancoronoviru hecho la vistima buscando convenio eso',\n",
              " 'wuhancoronoviru http twitter com goodlast hope statu',\n",
              " 'chines citizen share method cure wuhancoronoviru bring garlic water boil drink cup day thi ordinari fakenew spread around social media china http twitter com kui yang statu',\n",
              " 'wuhancoronoviru new threat it extens simmer panic i experi everi winter leav hous prepar travers bio toxic environ',\n",
              " 'it seem number death coronaviru patient china chang regularli wuhancoronoviru',\n",
              " 'para ficar de aviso ao maluco que ficaram inventando n mero de infectado e morto ela n tem freio autom tico n ter que ser contida descartem essa lorota de que se deixar ela perd coronaviru coronarviru coronaoutbreak brasil wuhancoronoviru pic twitter com deltejabh',\n",
              " 'we realli gonna trust california quarantin american fli america possibl w coronaviru ca even keep mexican china wuhan wuhancoronoviru wuhanviru',\n",
              " 'can cdcgov travelgov pleas explain usa accept plane willingli ground zero locat rapidli spread coronaviru kill sever peopl hospit mani wuhanoutbreak wuhancoronoviru wuhanchinahttp twitter com livecrisisnew statu',\n",
              " 'your job super high risk never work without mask goggl rmb viru could notic symptom even fever wuhancoronoviru',\n",
              " 'the ppl thread said mask work ridicul ye mask the best way stop u catch wuhancoronoviru wash hand help http twitter com apriloa statu',\n",
              " 'wuhancoronoviru pic twitter com foaspocwr',\n",
              " 'addawordruinabook wuhan anim farm fallontonight wuhancoronoviru pic twitter com ufmdssro',\n",
              " 'almost hong kong patient wuhancoronoviru come mainland they hongkong they peopl come infect us there reason nurs risk life serv china http twitter com cnni statu',\n",
              " 'coronaviru wuhancoronoviru http moneymaven io mishtalk econom hundr viru carri plane head us london pari vancouv ejnxiubmhk cunpwjclna',\n",
              " 'esto tien que ser co el equipo de f tbol de wuhancoronoviru llegar ana m laga hacer la pretemporada http www elmundo es deport futbol edcfccafbcf html',\n",
              " 'mr diy hand million mask free combat viru http www thestar com news nation mr diy hand million mask free combat viru xjyfqgv twitter thank mr diy salut wuhancoronoviru wuhanoutbreak wuhan',\n",
              " 'the continu open border like airport mean influx probabl wuhancoronoviru carrier hk thi put hker matter polit spectrum high risk the medic sector face unbear pressur collaps hker suffer',\n",
              " 'we live china lie wuhan ist like hell more peopl die liwenliang coronaviru lie help so wuhan wuhancoronoviru http twitter com wangzhian statu',\n",
              " 'wuhancoronoviru chinaoutbreak virus fact pic twitter com mlnsriocp',\n",
              " 'corona viru critic updat misheldbyt deceptionbyt qanon qarmi panicinchina wearethenewsnow qnew coronaviru q wwgwga wuhanoutbreak coronavirusoutbreak quarantin wuhancoronoviru seektruthcuzdeceptionbyt http youtu xobeazfivg via youtub',\n",
              " 'wuhanviru wuhancoronoviru wuflu',\n",
              " 'respect be honest easi china wuhancoronoviru china soshk',\n",
              " 'chines doctor li wenliang wuhan whistleblow ill coronaviru februari zacharykhubbard gematria broadcast coronaviru http youtu zsoq vg wuhanoutbreak coronavirustruth wuhancoronoviru chinaviru coronaviruschalleng chinawuhan',\n",
              " 'rip dr li wen liang wuhancoronoviru',\n",
              " 'new video caus spread coronaviru http youtu zngvaggqdw coronaviru corona viru health china chinaviru wuhan wuhancoronoviru pic twitter com caabyjt',\n",
              " 'ff wuhanpneumonia wuhan wuhancoronoviru',\n",
              " 'do look like joke wuhancoronoviru http twitter com vanessa zhanguk statu',\n",
              " 'calendar coronaviru http en ncov su see trash coronaviru wuhancoronoviru ncov ncov wuhanpnemoniap twitter com zvygcomc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OUrb6IpazU6",
        "colab_type": "code",
        "outputId": "59b90ce1-8344-43f3-82da-78aba66bbe26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "nltk.download('wordnet')    #code for Lemmatization\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizedWords = []\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for i in StemWords:\n",
        "  sent=''\n",
        "  for j in i:\n",
        "    sent=sent+\"\"+lemmatizer.lemmatize(j)\n",
        "    sent.strip()\n",
        "  lemmatizedWords.append(sent)\n",
        "\n",
        "import pandas as pd                 #Converting the DataFrame to a CSV o/p file \n",
        "df = pd.DataFrame(lemmatizedWords)\n",
        "csv_data = df.to_csv('out.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV",
        "colab_type": "text"
      },
      "source": [
        "# **Question 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX",
        "colab_type": "text"
      },
      "source": [
        "(30 points). Write a python program to conduct **syntax and structure analysis** of the clean text you just saved above. The syntax and structure analysis includes: \n",
        "\n",
        "(1) Parts of Speech (POS) Tagging: Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) Constituency Parsing and Dependency Parsing: print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) Named Entity Recognition: Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQKnPjPDHJHr",
        "colab_type": "code",
        "outputId": "9ce8124c-a545-46ab-d995-8ba852270c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Write your code here\n",
        "# Parts of Speech Code\n",
        "#3.1\n",
        "POS = []\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "for i in range(len(lemmatizedWords)):\n",
        "  tokens = nltk.word_tokenize( lemmatizedWords[i] )\n",
        "  pos_tags = nltk.pos_tag( tokens )\n",
        "  POS.append(pos_tags)\n",
        "POS"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('covid', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('pleas', 'NNS'),\n",
              "  ('stop', 'VBP'),\n",
              "  ('use', 'NN'),\n",
              "  ('abbrevi', 'NN'),\n",
              "  ('cover', 'NN'),\n",
              "  ('ccp', 'NN'),\n",
              "  ('crime', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('liuyun', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('chinaviru', 'NN'),\n",
              "  ('chinaziviru', 'NN'),\n",
              "  ('chinacoronaviru', 'NN'),\n",
              "  ('chinapneumonia', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('wuhansar', 'NN'),\n",
              "  ('wuhanvirusp', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('fxnbfbgh', 'NN')],\n",
              " [('najwa', 'JJ'),\n",
              "  ('niejsz', 'MD'),\n",
              "  ('na', 'VB'),\n",
              "  ('wieci', 'JJ'),\n",
              "  ('targi', 'NN'),\n",
              "  ('komunikacji', 'NN'),\n",
              "  ('mobilnej', 'NN'),\n",
              "  ('mwc', 'NN'),\n",
              "  ('w', 'NN'),\n",
              "  ('barceloni', 'NN'),\n",
              "  ('zostan', 'NNP'),\n",
              "  ('odwo', 'NN'),\n",
              "  ('ane', 'NN'),\n",
              "  ('w', 'NN'),\n",
              "  ('tym', 'NN'),\n",
              "  ('roku', 'NN'),\n",
              "  ('ze', 'NN'),\n",
              "  ('wzgl', 'NN'),\n",
              "  ('du', 'NN'),\n",
              "  ('na', 'TO'),\n",
              "  ('ryzyko', 'VB'),\n",
              "  ('koronawirusa', 'FW'),\n",
              "  ('w', 'FW'),\n",
              "  ('obawi', 'FW'),\n",
              "  ('przed', 'VBN'),\n",
              "  ('wirusem', 'NN'),\n",
              "  ('wiel', 'NN'),\n",
              "  ('znanych', 'NN'),\n",
              "  ('firm', 'NN'),\n",
              "  ('odwo', 'VBD'),\n",
              "  ('ju', 'JJ'),\n",
              "  ('sw', 'NN'),\n",
              "  ('j', 'NN'),\n",
              "  ('udzia', 'JJ'),\n",
              "  ('w', 'NN'),\n",
              "  ('wiatowym', 'NN'),\n",
              "  ('kongresi', 'NN'),\n",
              "  ('mobilnym', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('grossstadthex', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN')],\n",
              " [('crit', 'NN'),\n",
              "  ('en', 'VBZ'),\n",
              "  ('the', 'DT'),\n",
              "  ('eye', 'NN'),\n",
              "  ('dark', 'NN'),\n",
              "  ('de', 'IN'),\n",
              "  ('dean', 'FW'),\n",
              "  ('koontz', 'FW'),\n",
              "  ('suit', 'NN'),\n",
              "  ('un', 'JJ'),\n",
              "  ('viru', 'NN'),\n",
              "  ('appel', 'NN'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('velopp', 'NN'),\n",
              "  ('dan', 'NN'),\n",
              "  ('le', 'NN'),\n",
              "  ('laboratoir', 'JJ'),\n",
              "  ('militair', 'NN'),\n",
              "  ('de', 'IN'),\n",
              "  ('wuhan', 'FW'),\n",
              "  ('en', 'FW'),\n",
              "  ('chine', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('reallygrac', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('fall', 'VB'),\n",
              "  ('new', 'JJ'),\n",
              "  ('case', 'NN'),\n",
              "  ('rais', 'VBZ'),\n",
              "  ('hope', 'VBP'),\n",
              "  ('viru', 'JJ'),\n",
              "  ('outbreak', 'JJ'),\n",
              "  ('china', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('apnew', 'VBD'),\n",
              "  ('com', 'JJ'),\n",
              "  ('cdfdceabdeaa', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN')],\n",
              " [('acceler', 'NN'),\n",
              "  ('research', 'NN'),\n",
              "  ('innov', 'NN'),\n",
              "  ('mere', 'FW'),\n",
              "  ('buzz', 'NN'),\n",
              "  ('word', 'NN'),\n",
              "  ('sound', 'NN'),\n",
              "  ('impress', 'JJ'),\n",
              "  ('mass', 'NN'),\n",
              "  ('you', 'PRP'),\n",
              "  ('influenc', 'VBP'),\n",
              "  ('chines', 'NNS'),\n",
              "  ('govern', 'NNS'),\n",
              "  ('and', 'CC'),\n",
              "  ('everyon', 'NN'),\n",
              "  ('know', 'VBP'),\n",
              "  ('shameony', 'NN'),\n",
              "  ('wuhancoronov', 'NN'),\n",
              "  ('ru', 'NN'),\n",
              "  ('china', 'NN')],\n",
              " [('coronaraviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('youtu', 'NN'),\n",
              "  ('zulwkdbbi', 'NN'),\n",
              "  ('coronaraviru', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('chinawuhan', 'NN'),\n",
              "  ('covi', 'NN'),\n",
              "  ('covid', 'NN'),\n",
              "  ('valentin', 'NN'),\n",
              "  ('wuhancoronovirusmalaysia', 'NN'),\n",
              "  ('wuhanviru', 'NN'),\n",
              "  ('coronaviru', 'NN')],\n",
              " [('se', 'JJ'),\n",
              "  ('suspend', 'NN'),\n",
              "  ('el', 'NN'),\n",
              "  ('mwc', 'NN'),\n",
              "  ('el', 'FW'),\n",
              "  ('gp', 'NN'),\n",
              "  ('de', 'IN'),\n",
              "  ('china', 'FW'),\n",
              "  ('se', 'FW'),\n",
              "  ('suspend', 'VBP'),\n",
              "  ('que', 'NN'),\n",
              "  ('no', 'DT'),\n",
              "  ('dicen', 'NN'),\n",
              "  ('del', 'VBZ'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('covid', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN')],\n",
              " [('do', 'VB'),\n",
              "  ('rememb', 'NNS'),\n",
              "  ('wuhan', 'VB'),\n",
              "  ('protest', 'JJS'),\n",
              "  ('do', 'VBP'),\n",
              "  ('rememb', 'VB'),\n",
              "  ('ccp', 'VB'),\n",
              "  ('ignor', 'JJ'),\n",
              "  ('citizen', 'JJ'),\n",
              "  ('demand', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('www', 'VBP'),\n",
              "  ('googl', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('amp', 'NN'),\n",
              "  ('www', 'NN'),\n",
              "  ('bbc', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('news', 'NN'),\n",
              "  ('amp', 'NN'),\n",
              "  ('blog', 'NN'),\n",
              "  ('china', 'NN'),\n",
              "  ('blog', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('youtu', 'NN'),\n",
              "  ('zvfavspu', 'NN'),\n",
              "  ('and', 'CC'),\n",
              "  ('wuhancoronoviru', 'JJ'),\n",
              "  ('break', 'NN'),\n",
              "  ('ccp', 'NN'),\n",
              "  ('still', 'RB'),\n",
              "  ('ignor', 'JJ'),\n",
              "  ('citizen', 'JJ'),\n",
              "  ('demand', 'NN'),\n",
              "  ('human', 'JJ'),\n",
              "  ('right', 'JJ'),\n",
              "  ('democraci', 'NN'),\n",
              "  ('necessari', 'NNS'),\n",
              "  ('everyon', 'VBP')],\n",
              " [('let', 'VB'),\n",
              "  ('focu', 'PRP'),\n",
              "  ('wuhancoronoviru', 'VB'),\n",
              "  ('countri', 'JJ'),\n",
              "  ('secur', 'NNS'),\n",
              "  ('elect', 'VBP')],\n",
              " [('our', 'PRP$'),\n",
              "  ('team', 'NN'),\n",
              "  ('humbl', 'NN'),\n",
              "  ('ask', 'NN'),\n",
              "  ('help', 'NN'),\n",
              "  ('peopl', 'VB'),\n",
              "  ('china', 'JJ'),\n",
              "  ('lack', 'NN'),\n",
              "  ('mask', 'NN'),\n",
              "  ('protect', 'VBP'),\n",
              "  ('gear', 'JJ'),\n",
              "  ('fight', 'NN'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('pleas', 'NNS'),\n",
              "  ('kindli', 'VBP'),\n",
              "  ('make', 'VBP'),\n",
              "  ('donat', 'JJ'),\n",
              "  ('thru', 'NN'),\n",
              "  ('offici', 'IN'),\n",
              "  ('websit', 'NN'),\n",
              "  ('contact', 'NN'),\n",
              "  ('us', 'PRP'),\n",
              "  ('detail', 'VBP'),\n",
              "  ('http', 'JJ'),\n",
              "  ('buff', 'NN'),\n",
              "  ('ly', 'NN'),\n",
              "  ('ukrn', 'JJ'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('protectthechildrenp', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('wykbvvb', 'NN')],\n",
              " [('wuhancoronoviru', 'JJ'),\n",
              "  ('time', 'NN'),\n",
              "  ('contagi', 'NN'),\n",
              "  ('sar', 'NN'),\n",
              "  ('howev', 'NN'),\n",
              "  ('carri', 'NN'),\n",
              "  ('lame', 'JJ'),\n",
              "  ('duck', 'NN'),\n",
              "  ('govt', 'NN'),\n",
              "  ('chosen', 'VBN'),\n",
              "  ('sit', 'NN'),\n",
              "  ('sidelin', 'NN'),\n",
              "  ('noth', 'DT'),\n",
              "  ('sustain', 'VBP'),\n",
              "  ('suffici', 'JJ'),\n",
              "  ('mask', 'NN'),\n",
              "  ('suppli', 'NN'),\n",
              "  ('all', 'DT'),\n",
              "  ('measur', 'VBP'),\n",
              "  ('r', 'NN'),\n",
              "  ('match', 'NN'),\n",
              "  ('w', 'NN'),\n",
              "  ('sar', 'VBZ'),\n",
              "  ('no', 'DT'),\n",
              "  ('wonder', 'NN'),\n",
              "  ('bloomberg', 'NN'),\n",
              "  ('said', 'VBD'),\n",
              "  ('hk', 'JJ'),\n",
              "  ('govt', 'NN'),\n",
              "  ('show', 'NN'),\n",
              "  ('symptom', 'JJ'),\n",
              "  ('fail', 'NN'),\n",
              "  ('state', 'NN')],\n",
              " [('neverforget', 'NN'),\n",
              "  ('neverforg', 'JJ'),\n",
              "  ('hkpoliceterror', 'NN'),\n",
              "  ('hkpolicest', 'JJS'),\n",
              "  ('standwithhongkong', 'NN'),\n",
              "  ('hongkong', 'JJ'),\n",
              "  ('china', 'JJ'),\n",
              "  ('terrorist', 'JJ'),\n",
              "  ('antichinazi', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('aaronmcn', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('first', 'RB'),\n",
              "  ('hand', 'NN'),\n",
              "  ('insight', 'NN'),\n",
              "  ('like', 'IN'),\n",
              "  ('insid', 'JJ'),\n",
              "  ('coronaviru', 'JJ'),\n",
              "  ('field', 'NN'),\n",
              "  ('hospit', 'VBD'),\n",
              "  ('xhnew', 'JJ'),\n",
              "  ('report', 'NN'),\n",
              "  ('xu', 'NNP'),\n",
              "  ('zeyu', 'NNP'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('wuhanjiay', 'NN'),\n",
              "  ('hospit', 'NN'),\n",
              "  ('outbreak', 'JJ'),\n",
              "  ('wuhancoronov', 'NN'),\n",
              "  ('ru', 'NN'),\n",
              "  ('chinadaili', 'NN'),\n",
              "  ('chinadailynew', 'VBD'),\n",
              "  ('http', 'JJ'),\n",
              "  ('www', 'NN'),\n",
              "  ('facebook', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('watch', 'NN'),\n",
              "  ('v', 'NN')],\n",
              " [('oto', 'NN'),\n",
              "  ('jak', 'NN'),\n",
              "  ('model', 'NN'),\n",
              "  ('komputerow', 'NN'),\n",
              "  ('symuluj', 'NN'),\n",
              "  ('przysz', 'NN'),\n",
              "  ('e', 'NN'),\n",
              "  ('rozprzestrzeniani', 'NN'),\n",
              "  ('si', 'NN'),\n",
              "  ('nowego', 'JJ'),\n",
              "  ('koronawirusa', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('here', 'RB'),\n",
              "  ('how', 'WRB'),\n",
              "  ('comput', 'JJ'),\n",
              "  ('model', 'NN'),\n",
              "  ('simul', 'NN'),\n",
              "  ('futur', 'NNS'),\n",
              "  ('spread', 'VBD'),\n",
              "  ('new', 'JJ'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('translat', 'JJ'),\n",
              "  ('googl', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('translat', 'JJ'),\n",
              "  ('hl', 'NN'),\n",
              "  ('pl', 'NN'),\n",
              "  ('sl', 'JJ'),\n",
              "  ('auto', 'NN'),\n",
              "  ('tl', 'NN'),\n",
              "  ('pl', 'NN'),\n",
              "  ('u', 'JJ'),\n",
              "  ('http', 'VBZ'),\n",
              "  ('a', 'DT'),\n",
              "  ('f', 'JJ'),\n",
              "  ('fwww', 'JJ'),\n",
              "  ('scientificamerican', 'JJ'),\n",
              "  ('com', 'NN'),\n",
              "  ('farticl', 'NN'),\n",
              "  ('fhere', 'RB'),\n",
              "  ('comput', 'VBN'),\n",
              "  ('model', 'NN'),\n",
              "  ('simul', 'NN'),\n",
              "  ('futur', 'NNS'),\n",
              "  ('spread', 'VBD'),\n",
              "  ('new', 'JJ'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('f', 'NN'),\n",
              "  ('famp', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('www', 'JJ'),\n",
              "  ('scientificamerican', 'JJ'),\n",
              "  ('com', 'NN'),\n",
              "  ('articl', 'NN'),\n",
              "  ('here', 'RB'),\n",
              "  ('comput', 'VBD'),\n",
              "  ('model', 'NN'),\n",
              "  ('simul', 'NN'),\n",
              "  ('futur', 'NNS'),\n",
              "  ('spread', 'VBD'),\n",
              "  ('new', 'JJ'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('amp', 'NN')],\n",
              " [('not', 'RB'),\n",
              "  ('anoth', 'DT'),\n",
              "  ('add', 'JJ'),\n",
              "  ('oil', 'NN'),\n",
              "  ('fight', 'NN'),\n",
              "  ('diseas', 'RB'),\n",
              "  ('spread', 'VBP'),\n",
              "  ('like', 'IN'),\n",
              "  ('fire', 'NN'),\n",
              "  ('ad', 'NN'),\n",
              "  ('oil', 'NN'),\n",
              "  ('appropri', 'VBP'),\n",
              "  ('tri', 'NN'),\n",
              "  ('give', 'JJ'),\n",
              "  ('bless', 'NN'),\n",
              "  ('the', 'DT'),\n",
              "  ('act', 'NN'),\n",
              "  ('wuhan', 'WRB'),\n",
              "  ('rise', 'NN'),\n",
              "  ('recoveri', 'NN'),\n",
              "  ('know', 'VBP'),\n",
              "  ('classic', 'JJ'),\n",
              "  ('knowledg', 'NN'),\n",
              "  ('wuhancoronov', 'NN'),\n",
              "  ('ru', 'NN'),\n",
              "  ('chinesep', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('stjlsolbc', 'NN')],\n",
              " [('day', 'NN'),\n",
              "  ('apart', 'RB'),\n",
              "  ('prove', 'VB'),\n",
              "  ('day', 'NN'),\n",
              "  ('quarantin', 'NN'),\n",
              "  ('long', 'RB'),\n",
              "  ('enough', 'JJ'),\n",
              "  ('time', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('covid', 'NN'),\n",
              "  ('ccp', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('wuhanviru', 'NN'),\n",
              "  ('cdcemerg', 'NN'),\n",
              "  ('who', 'WP'),\n",
              "  ('whitehous', 'JJ'),\n",
              "  ('foxnew', 'NN'),\n",
              "  ('cnn', 'NN')],\n",
              " [('some', 'DT'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('evacue', 'VBP'),\n",
              "  ('ask', 'NN'),\n",
              "  ('whi', 'NN'),\n",
              "  ('they', 'PRP'),\n",
              "  ('aren', 'VBP'),\n",
              "  ('be', 'VB'),\n",
              "  ('test', 'JJ'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('dnyuz', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('evacue', 'NN'),\n",
              "  ('ask', 'NN'),\n",
              "  ('arent', 'JJ'),\n",
              "  ('test', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('coronaviruswuhan', 'NN'),\n",
              "  ('coronavirususa', 'NN'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('dnyuzcom', 'NN')],\n",
              " [('i', 'JJ'),\n",
              "  ('bing', 'VBG'),\n",
              "  ('watch', 'NN'),\n",
              "  ('chernobyl', 'VBD'),\n",
              "  ('the', 'DT'),\n",
              "  ('parallel', 'JJ'),\n",
              "  ('amaz', 'NN'),\n",
              "  ('a', 'DT'),\n",
              "  ('communist', 'NN'),\n",
              "  ('regim', 'NN'),\n",
              "  ('put', 'VBD'),\n",
              "  ('face', 'NN'),\n",
              "  ('save', 'NN'),\n",
              "  ('good', 'JJ'),\n",
              "  ('parti', 'NN'),\n",
              "  ('anyth', 'NN'),\n",
              "  ('els', 'NNS'),\n",
              "  ('kill', 'VB'),\n",
              "  ('process', 'NN'),\n",
              "  ('chill', 'NN'),\n",
              "  ('coronavirusu', 'VBZ'),\n",
              "  ('coronavirusdeath', 'NN'),\n",
              "  ('coronaviruswuhan', 'NN'),\n",
              "  ('coronavirusuk', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN')],\n",
              " [('cn', 'NN'),\n",
              "  ('initi', 'NN'),\n",
              "  ('motiv', 'NNS'),\n",
              "  ('make', 'VBP'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('kill', 'NN'),\n",
              "  ('ppl', 'VBZ'),\n",
              "  ('tw', 'JJ'),\n",
              "  ('bcoz', 'NN'),\n",
              "  ('want', 'VBP'),\n",
              "  ('use', 'NN'),\n",
              "  ('militari', 'NN'),\n",
              "  ('forc', 'NN'),\n",
              "  ('howev', 'NN'),\n",
              "  ('ccp', 'NN'),\n",
              "  ('manag', 'NN'),\n",
              "  ('abil', 'VBZ'),\n",
              "  ('alway', 'RB'),\n",
              "  ('poor', 'JJ'),\n",
              "  ('caus', 'NNS'),\n",
              "  ('viru', 'VBP'),\n",
              "  ('leak', 'JJ'),\n",
              "  ('wuhanplab', 'NN'),\n",
              "  ('harm', 'NN'),\n",
              "  ('ppl', 'NN'),\n",
              "  ('coronavirustruth', 'NN')],\n",
              " [('hongkong', 'JJ'),\n",
              "  ('hospit', 'NN'),\n",
              "  ('isol', 'JJ'),\n",
              "  ('ward', 'NN'),\n",
              "  ('u', 'JJ'),\n",
              "  ('need', 'VBP'),\n",
              "  ('plastic', 'JJ'),\n",
              "  ('sheet', 'NN'),\n",
              "  ('world', 'NN'),\n",
              "  ('class', 'NN'),\n",
              "  ('citi', 'NN'),\n",
              "  ('right', 'RB'),\n",
              "  ('soshk', 'JJ'),\n",
              "  ('carrielam', 'NN'),\n",
              "  ('useless', 'JJ'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('coronavirusoutbreakp', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('kvrdmsrjt', 'NN')],\n",
              " [('covid', 'JJ'),\n",
              "  ('coronaviruschina', 'NN'),\n",
              "  ('wuhanviru', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('michaelcbend', 'VBP'),\n",
              "  ('statu', 'NN')],\n",
              " [('updat', 'JJ'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('support', 'NN'),\n",
              "  ('websit', 'VBD'),\n",
              "  ('visit', 'NN'),\n",
              "  ('post', 'NN'),\n",
              "  ('ur', 'JJ'),\n",
              "  ('voic', 'NN'),\n",
              "  ('wuhanviru', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('cultech', 'NN'),\n",
              "  ('biz', 'NN'),\n",
              "  ('messag', 'NN'),\n",
              "  ('wuhan', 'NN')],\n",
              " [('http', 'NN'),\n",
              "  ('www', 'NN'),\n",
              "  ('googl', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('amp', 'NN'),\n",
              "  ('amp', 'NN'),\n",
              "  ('theguardian', 'JJ'),\n",
              "  ('com', 'NN'),\n",
              "  ('world', 'NN'),\n",
              "  ('feb', 'NN'),\n",
              "  ('london', 'VBP'),\n",
              "  ('coronaviru', 'JJ'),\n",
              "  ('patient', 'NN'),\n",
              "  ('turn', 'NN'),\n",
              "  ('hospit', 'JJ'),\n",
              "  ('uber', 'NNP'),\n",
              "  ('taxi', 'NN'),\n",
              "  ('it', 'PRP'),\n",
              "  ('difficult', 'JJ'),\n",
              "  ('thing', 'NN'),\n",
              "  ('world', 'NN'),\n",
              "  ('make', 'VBP'),\n",
              "  ('ppl', 'NN'),\n",
              "  ('obey', 'NN'),\n",
              "  ('rule', 'NN'),\n",
              "  ('china', 'VBP'),\n",
              "  ('coronaviruslondon', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('pic', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('cwnkhdqbw', 'NN')],\n",
              " [('thi', 'JJ'),\n",
              "  ('sad', 'NN'),\n",
              "  ('i', 'NN'),\n",
              "  ('understand', 'VBP'),\n",
              "  ('men', 'NNS'),\n",
              "  ('black', 'JJ'),\n",
              "  ('profil', 'NN'),\n",
              "  ('gear', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('byron', 'NN'),\n",
              "  ('wan', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('hope', 'NN'),\n",
              "  ('wrong', 'JJ'),\n",
              "  ('god', 'NN'),\n",
              "  ('bless', 'NN'),\n",
              "  ('us', 'PRP'),\n",
              "  ('us', 'PRP'),\n",
              "  ('wuhancoronoviru', 'VBP'),\n",
              "  ('wuhanviru', 'JJ'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('drericd', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('for', 'IN'),\n",
              "  ('valentinesday', 'NN'),\n",
              "  ('hongkong', 'JJ'),\n",
              "  ('r', 'NN'),\n",
              "  ('queu', 'NN'),\n",
              "  ('onlin', 'IN'),\n",
              "  ('person', 'NN'),\n",
              "  ('face', 'NN'),\n",
              "  ('mask', 'NN'),\n",
              "  ('at', 'IN'),\n",
              "  ('given', 'VBN'),\n",
              "  ('time', 'NN'),\n",
              "  ('r', 'NN'),\n",
              "  ('mil', 'NN'),\n",
              "  ('ppl', 'NN'),\n",
              "  ('ahead', 'RB'),\n",
              "  ('u', 'JJ'),\n",
              "  ('waitlist', 'NN'),\n",
              "  ('pharmaci', 'NN'),\n",
              "  ('mask', 'NN'),\n",
              "  ('carrielam', 'NN'),\n",
              "  ('said', 'VBD'),\n",
              "  ('gov', 'NN'),\n",
              "  ('still', 'RB'),\n",
              "  ('find', 'VB'),\n",
              "  ('wuhancoronoviru', 'JJ'),\n",
              "  ('hongkong', 'JJ'),\n",
              "  ('gov', 'NN'),\n",
              "  ('useless', 'JJ'),\n",
              "  ('pic', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('xgbzswo', 'NN')],\n",
              " [('i', 'NN'),\n",
              "  ('safe', 'JJ'),\n",
              "  ('nuclear', 'JJ'),\n",
              "  ('bunker', 'NN'),\n",
              "  ('think', 'VBP'),\n",
              "  ('kick', 'VB'),\n",
              "  ('franci', 'NN'),\n",
              "  ('coppola', 'NN'),\n",
              "  ('stop', 'NN'),\n",
              "  ('talk', 'NN'),\n",
              "  ('make', 'VBP'),\n",
              "  ('sequel', 'NN'),\n",
              "  ('one', 'CD'),\n",
              "  ('from', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('heart', 'NN'),\n",
              "  ('shut', 'NN'),\n",
              "  ('franci', 'NN'),\n",
              "  ('valentinesday', 'NN'),\n",
              "  ('wuhancoronaviru', 'VBD'),\n",
              "  ('wuhancoronoviru', 'JJ'),\n",
              "  ('coronoavirusoutbreakhttp', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('wsj', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('can', 'MD'),\n",
              "  ('believ', 'VB'),\n",
              "  ('arianagrand', 'VB'),\n",
              "  ('trend', 'NN'),\n",
              "  ('co', 'NN'),\n",
              "  ('dress', 'NN'),\n",
              "  ('grammi', 'NN'),\n",
              "  ('asian', 'JJ'),\n",
              "  ('contin', 'NN'),\n",
              "  ('world', 'NN'),\n",
              "  ('peopl', 'NN'),\n",
              "  ('die', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN')],\n",
              " [('terrifi', 'NNS'),\n",
              "  ('wuhanlockdown', 'VBP'),\n",
              "  ('wuhancoronoviru', 'JJ'),\n",
              "  ('wuhanquarantin', 'NN'),\n",
              "  ('wuhanoutbreak', 'NN'),\n",
              "  ('coronaoutbreak', 'NN'),\n",
              "  ('coronavirusoutbreak', 'NN'),\n",
              "  ('wuhanpnemoniahttp', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('bnodesk', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('break', 'JJ'),\n",
              "  ('news', 'NN'),\n",
              "  ('pagi', 'NN'),\n",
              "  ('ini', 'NN'),\n",
              "  ('dokter', 'NN'),\n",
              "  ('paparkan', 'NN'),\n",
              "  ('kondisi', 'FW'),\n",
              "  ('pasien', 'NN'),\n",
              "  ('di', 'NN'),\n",
              "  ('jambi', 'NN'),\n",
              "  ('yang', 'NN'),\n",
              "  ('diduga', 'NN'),\n",
              "  ('kena', 'NN'),\n",
              "  ('viru', 'NN'),\n",
              "  ('corona', 'NN'),\n",
              "  ('tribunjambi', 'NN'),\n",
              "  ('viruscorona', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('jambi', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('wuhanpneumonia', 'NN'),\n",
              "  ('coronaoutbreak', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('jambi', 'NN'),\n",
              "  ('tribunnew', 'VBD'),\n",
              "  ('com', 'JJ'),\n",
              "  ('break', 'JJ'),\n",
              "  ('news', 'NN'),\n",
              "  ('pagi', 'NN'),\n",
              "  ('ini', 'NN'),\n",
              "  ('dokter', 'NN'),\n",
              "  ('paparkan', 'NN'),\n",
              "  ('kondisi', 'FW'),\n",
              "  ('pasien', 'NN'),\n",
              "  ('di', 'NN'),\n",
              "  ('jambi', 'NN'),\n",
              "  ('yang', 'NN'),\n",
              "  ('diduga', 'NN'),\n",
              "  ('kena', 'NN'),\n",
              "  ('viru', 'NN'),\n",
              "  ('corona', 'NN'),\n",
              "  ('lewat', 'NN'),\n",
              "  ('tribunjambiku', 'NN')],\n",
              " [('ncov', 'CC'),\n",
              "  ('full', 'JJ'),\n",
              "  ('genom', 'NN'),\n",
              "  ('sequenc', 'NN'),\n",
              "  ('analyz', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('who', 'WP'),\n",
              "  ('statu', 'VBD')],\n",
              " [('ecmo', 'NN'),\n",
              "  ('deliv', 'NN'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('jinyintan', 'NN'),\n",
              "  ('hospit', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('put', 'VB'),\n",
              "  ('perspect', 'JJ'),\n",
              "  ('top', 'JJ'),\n",
              "  ('shanghai', 'NN'),\n",
              "  ('hospit', 'NN'),\n",
              "  ('zhongshan', 'NN'),\n",
              "  ('on', 'IN'),\n",
              "  ('yo', 'JJ'),\n",
              "  ('male', 'JJ'),\n",
              "  ('patient', 'NN'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('rescu', 'NN'),\n",
              "  ('ecmo', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('bit', 'NN'),\n",
              "  ('ly', 'JJ'),\n",
              "  ('gqqpmi', 'NN'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('ncov', 'JJ'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('pic', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('guazcknba', 'NN')],\n",
              " [('separ', 'NN'),\n",
              "  ('camp', 'NN'),\n",
              "  ('patient', 'NN'),\n",
              "  ('suspect', 'NN'),\n",
              "  ('infect', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN')],\n",
              " [('true', 'JJ'),\n",
              "  ('our', 'PRP$'),\n",
              "  ('worri', 'NN'),\n",
              "  ('meant', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('spread', 'NN'),\n",
              "  ('rapid', 'JJ'),\n",
              "  ('mode', 'NN')],\n",
              " [('coronarviru', 'NN'),\n",
              "  ('coronaoutbreak', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('coronaviruschinahttp', 'NN'),\n",
              "  ('www', 'NN'),\n",
              "  ('fatimacoeg', 'NN'),\n",
              "  ('site', 'NN'),\n",
              "  ('viru', 'NN'),\n",
              "  ('corona', 'NN'),\n",
              "  ('buat', 'NN'),\n",
              "  ('kota', 'NN'),\n",
              "  ('ini', 'NN'),\n",
              "  ('seperti', 'NN'),\n",
              "  ('kota', 'NN'),\n",
              "  ('html', 'NN')],\n",
              " [('wuhancoronoviru', 'JJ'),\n",
              "  ('wuhandonteatunclean', 'JJ'),\n",
              "  ('food', 'NN'),\n",
              "  ('read', 'VB'),\n",
              "  ('bibl', 'NN'),\n",
              "  ('chapter', 'NN'),\n",
              "  ('leviticusp', 'VBP'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('qniojugiz', 'NN')],\n",
              " [('a', 'DT'),\n",
              "  ('real', 'JJ'),\n",
              "  ('time', 'NN'),\n",
              "  ('map', 'NN'),\n",
              "  ('bout', 'IN'),\n",
              "  ('current', 'JJ'),\n",
              "  ('situat', 'NN'),\n",
              "  ('coronaoutbreak', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('gisanddata', 'NN'),\n",
              "  ('map', 'NN'),\n",
              "  ('arcgi', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('app', 'RB'),\n",
              "  ('opsdashboard', 'RB'),\n",
              "  ('index', 'NN'),\n",
              "  ('html', 'VBD'),\n",
              "  ('bdafdbeecf', 'JJ'),\n",
              "  ('coronarviru', 'NN'),\n",
              "  ('coronaoutbreak', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN')],\n",
              " [('all', 'DT'),\n",
              "  ('i', 'NNS'),\n",
              "  ('say', 'VBP'),\n",
              "  ('vancouv', 'IN'),\n",
              "  ('major', 'JJ'),\n",
              "  ('citi', 'NN'),\n",
              "  ('canada', 'NN'),\n",
              "  ('resembl', 'NN'),\n",
              "  ('wuhan', 'JJ'),\n",
              "  ('start', 'NN'),\n",
              "  ('provis', 'NN'),\n",
              "  ('now', 'RB'),\n",
              "  ('coronarviru', 'VBZ'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('itsalreadyher', 'NN')],\n",
              " [('januari', 'NN'),\n",
              "  ('updat', 'JJ'),\n",
              "  ('bbcworld', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('coronavirusoutbreakhttp', 'NN'),\n",
              "  ('www', 'NN'),\n",
              "  ('youtub', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('watch', 'NN'),\n",
              "  ('v', 'NN'),\n",
              "  ('jawpcypfqc', 'NN')],\n",
              " [('laurelchor', 'NN'),\n",
              "  ('veri', 'NN'),\n",
              "  ('unsettl', 'JJ'),\n",
              "  ('news', 'NN'),\n",
              "  ('today', 'NN'),\n",
              "  ('abt', 'IN'),\n",
              "  ('fast', 'JJ'),\n",
              "  ('transmiss', 'JJ'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('yr', 'NN'),\n",
              "  ('insight', 'NN'),\n",
              "  ('thought', 'VBD'),\n",
              "  ('abt', 'RB'),\n",
              "  ('make', 'JJ'),\n",
              "  ('think', 'NN'),\n",
              "  ('mani', 'NN'),\n",
              "  ('well', 'RB'),\n",
              "  ('known', 'VBN'),\n",
              "  ('ppl', 'NN'),\n",
              "  ('usa', 'JJ'),\n",
              "  ('europ', 'NN'),\n",
              "  ('publicli', 'NN'),\n",
              "  ('ask', 'NN'),\n",
              "  ('yr', 'PRP'),\n",
              "  ('question', 'VBP'),\n",
              "  ('what', 'WP'),\n",
              "  ('take', 'VBP'),\n",
              "  ('chang', 'JJ'),\n",
              "  ('behavior', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('laurelchor', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('tom', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('go', 'VBP'),\n",
              "  ('shit', 'JJ'),\n",
              "  ('storm', 'NN')],\n",
              " [('china', 'NNS'),\n",
              "  ('say', 'VBP'),\n",
              "  ('coronaviru', 'JJ'),\n",
              "  ('spread', 'NN'),\n",
              "  ('symptom', 'NN'),\n",
              "  ('show', 'VBP'),\n",
              "  ('death', 'NN'),\n",
              "  ('toll', 'NN'),\n",
              "  ('grow', 'NN'),\n",
              "  ('th', 'VBD'),\n",
              "  ('us', 'PRP'),\n",
              "  ('case', 'NN'),\n",
              "  ('confirm', 'NN'),\n",
              "  ('coronarviru', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN')],\n",
              " [('wuhancoronoviru', 'NN'),\n",
              "  ('as', 'IN'),\n",
              "  ('chines', 'NNS'),\n",
              "  ('intern', 'JJ'),\n",
              "  ('student', 'NN'),\n",
              "  ('us', 'PRP'),\n",
              "  ('i', 'VBP'),\n",
              "  ('extrem', 'JJ'),\n",
              "  ('worri', 'NN'),\n",
              "  ('famili', 'NN'),\n",
              "  ('they', 'PRP'),\n",
              "  ('ask', 'VBP'),\n",
              "  ('stay', 'VBP'),\n",
              "  ('us', 'PRP'),\n",
              "  ('spring', 'NN'),\n",
              "  ('break', 'NN'),\n",
              "  ('told', 'VBD'),\n",
              "  ('one', 'CD'),\n",
              "  ('friend', 'NN'),\n",
              "  ('may', 'MD'),\n",
              "  ('infect', 'VB'),\n",
              "  ('i', 'JJ'),\n",
              "  ('wish', 'JJ'),\n",
              "  ('normal', 'JJ'),\n",
              "  ('fever', 'NN'),\n",
              "  ('thank', 'NN'),\n",
              "  ('famili', 'NN'),\n",
              "  ('healthi', 'NN'),\n",
              "  ('yet', 'RB')],\n",
              " [('ban', 'JJ'),\n",
              "  ('china', 'NN'),\n",
              "  ('peopl', 'NN'),\n",
              "  ('travel', 'NN'),\n",
              "  ('indonesia', 'NN'),\n",
              "  ('right', 'JJ'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('coronarviru', 'NN'),\n",
              "  ('wuhan', 'NN')],\n",
              " [('le', 'NN'),\n",
              "  ('bilan', 'NN'),\n",
              "  ('du', 'VBP'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('alourdit', 'NN'),\n",
              "  ('mort', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('williamyang', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('wuhanchalleng', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('million', 'CD'),\n",
              "  ('would', 'MD'),\n",
              "  ('fli', 'VB'),\n",
              "  ('wuhanchina', 'NNS'),\n",
              "  ('take', 'VB'),\n",
              "  ('train', 'NN'),\n",
              "  ('citi', 'NN'),\n",
              "  ('wash', 'NN'),\n",
              "  ('hand', 'NN'),\n",
              "  ('point', 'NN'),\n",
              "  ('use', 'NN'),\n",
              "  ('bathroom', 'NN'),\n",
              "  ('sever', 'NN'),\n",
              "  ('time', 'NN'),\n",
              "  ('eat', 'NN'),\n",
              "  ('chicken', 'NN'),\n",
              "  ('wing', 'VBG'),\n",
              "  ('hand', 'NN'),\n",
              "  ('sleep', 'JJ'),\n",
              "  ('f', 'NN'),\n",
              "  ('room', 'NN'),\n",
              "  ('sheet', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN')],\n",
              " [('wuhan', 'NN'),\n",
              "  ('wuhancoronoviru', 'WRB'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('cat', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('call', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('ban', 'VB'),\n",
              "  ('flight', 'NN'),\n",
              "  ('from', 'IN'),\n",
              "  ('china', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('australia', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('pm', 'NN'),\n",
              "  ('pressur', 'NN'),\n",
              "  ('stop', 'VB'),\n",
              "  ('flight', 'NN'),\n",
              "  ('australia', 'IN'),\n",
              "  ('china', 'NN'),\n",
              "  ('qanta', 'NN'),\n",
              "  ('reportedli', 'NN'),\n",
              "  ('prepar', 'NN'),\n",
              "  ('send', 'VBP'),\n",
              "  ('crew', 'NN'),\n",
              "  ('evacu', 'NN'),\n",
              "  ('australian', 'JJ'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('wuhanchinap', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('hwovqdjjuk', 'NN')],\n",
              " [('wuhan', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('pandem', 'NN'),\n",
              "  ('bioengin', 'NN'),\n",
              "  ('who', 'WP'),\n",
              "  ('behind', 'IN'),\n",
              "  ('china', 'NN'),\n",
              "  ('wuhancoronoviru', 'NNS'),\n",
              "  ('coronaviruswho', 'VBP'),\n",
              "  ('http', 'VBP'),\n",
              "  ('stateofthen', 'JJ'),\n",
              "  ('co', 'NN'),\n",
              "  ('p', 'NN')],\n",
              " [('number', 'NN'),\n",
              "  ('updat', 'JJ'),\n",
              "  ('china', 'NN'),\n",
              "  ('diagnos', 'NNS'),\n",
              "  ('suspect', 'VBP'),\n",
              "  ('death', 'NN'),\n",
              "  ('cure', 'NN'),\n",
              "  ('wuhan', 'VBP'),\n",
              "  ('wuhancoronoviru', 'WP'),\n",
              "  ('wuhanpneumonia', 'VBP'),\n",
              "  ('coronaviru', 'NN')],\n",
              " [('insight', 'JJ'),\n",
              "  ('piec', 'NN'),\n",
              "  ('nytopinion', 'NN'),\n",
              "  ('xi', 'NNP'),\n",
              "  ('authoritarian', 'JJ'),\n",
              "  ('govern', 'NN'),\n",
              "  ('model', 'NN'),\n",
              "  ('enabl', 'NN'),\n",
              "  ('global', 'JJ'),\n",
              "  ('outbreak', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('www', 'NN'),\n",
              "  ('nytim', 'JJ'),\n",
              "  ('com', 'JJ'),\n",
              "  ('opinion', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('china', 'NN'),\n",
              "  ('govern', 'JJ'),\n",
              "  ('html', 'NN')],\n",
              " [('daili', 'NN'),\n",
              "  ('updat', 'JJ'),\n",
              "  ('coronarviru', 'NN'),\n",
              "  ('pleas', 'NNS'),\n",
              "  ('safe', 'JJ'),\n",
              "  ('peopl', 'NN'),\n",
              "  ('maintain', 'NN'),\n",
              "  ('good', 'JJ'),\n",
              "  ('person', 'NN'),\n",
              "  ('hygien', 'JJ'),\n",
              "  ('stay', 'NN'),\n",
              "  ('home', 'NN'),\n",
              "  ('sick', 'NN'),\n",
              "  ('stat', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('pic', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('gtowhdd', 'NN')],\n",
              " [('coronarviru', 'NN'),\n",
              "  ('wuhancoronavirusoutbreak', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('wuhanhttp', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('plumwdhs', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('coronaviru', 'NN'),\n",
              "  ('outbreak', 'MD'),\n",
              "  ('spread', 'VB'),\n",
              "  ('global', 'JJ'),\n",
              "  ('http', 'NN'),\n",
              "  ('cnn', 'NN'),\n",
              "  ('rftssk', 'NN'),\n",
              "  ('corona', 'NN'),\n",
              "  ('coronaviruswho', 'NN'),\n",
              "  ('wuhancoronavirusoutbreak', 'VBP'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('wuhanpneumonia', 'NN'),\n",
              "  ('wuhanchina', 'IN'),\n",
              "  ('china', 'NNS'),\n",
              "  ('wuhanlockdown', 'JJ'),\n",
              "  ('wuhanoutbreak', 'JJ'),\n",
              "  ('fridaythought', 'NN')],\n",
              " [('wuhancoronoviru', 'NN'),\n",
              "  ('soshkhttp', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('ezracheungtoto', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('airindiain', 'NN'),\n",
              "  ('ai', 'NN'),\n",
              "  ('bring', 'VB'),\n",
              "  ('back', 'RP'),\n",
              "  ('indian', 'JJ'),\n",
              "  ('student', 'NN'),\n",
              "  ('wuhanchina', 'NN'),\n",
              "  ('enter', 'NN'),\n",
              "  ('india', 'VBP'),\n",
              "  ('airspac', 'NN'),\n",
              "  ('salut', 'NN'),\n",
              "  ('brave', 'VBP'),\n",
              "  ('crew', 'NN'),\n",
              "  ('air', 'NN'),\n",
              "  ('india', 'VBP'),\n",
              "  ('hardeepspuri', 'NN'),\n",
              "  ('coronarviru', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('coronaviruswho', 'NN'),\n",
              "  ('http', 'VBP'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('robinjindia', 'NN'),\n",
              "  ('statu', 'NN'),\n",
              "  ('pic', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('rirqlmga', 'NN')],\n",
              " [('ncov', 'JJ'),\n",
              "  ('coronarviru', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('pic', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('csmwlovz', 'NN')],\n",
              " [('real', 'JJ'),\n",
              "  ('sourc', 'NNS'),\n",
              "  ('coverag', 'VBP'),\n",
              "  ('corona', 'JJ'),\n",
              "  ('viru', 'NN'),\n",
              "  ('page', 'NN'),\n",
              "  ('follow', 'JJ'),\n",
              "  ('updat', 'JJ'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('ncov', 'NN'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('hubei', 'NN'),\n",
              "  ('breakinghttp', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('gibsfre', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('http', 'NN'),\n",
              "  ('www', 'NN'),\n",
              "  ('natur', 'JJ'),\n",
              "  ('com', 'NN'),\n",
              "  ('articl', 'NN'),\n",
              "  ('wohc', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN')],\n",
              " [('a', 'DT'),\n",
              "  ('sanit', 'NN'),\n",
              "  ('worker', 'NN'),\n",
              "  ('donat', 'NN'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('telegram', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('youtu', 'NN'),\n",
              "  ('b', 'NN'),\n",
              "  ('ymnfxdtta', 'NN')],\n",
              " [('be', 'VB'), ('safe', 'JJ'), ('everyon', 'NN'), ('wuhancoronoviru', 'NN')],\n",
              " [('wuhan', 'JJ'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('death', 'NN'),\n",
              "  ('toll', 'NN'),\n",
              "  ('rise', 'NN'),\n",
              "  ('china', 'VBP'),\n",
              "  ('new', 'JJ'),\n",
              "  ('fatal', 'JJ'),\n",
              "  ('cna', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('wuhanoutbreak', 'NN'),\n",
              "  ('wuhanflu', 'NN'),\n",
              "  ('wuhanflu', 'NN'),\n",
              "  ('ncov', 'JJ'),\n",
              "  ('coronoaviru', 'NN'),\n",
              "  ('wuhanhttp', 'NN'),\n",
              "  ('www', 'NN'),\n",
              "  ('channelnewsasia', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('news', 'NN'),\n",
              "  ('asia', 'NN'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('viru', 'FW'),\n",
              "  ('death', 'NN'),\n",
              "  ('toll', 'NN'),\n",
              "  ('rise', 'NN'),\n",
              "  ('china', 'NN'),\n",
              "  ('case', 'NN')],\n",
              " [('recoveri', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('coronarviru', 'NN'),\n",
              "  ('outpac', 'IN'),\n",
              "  ('death', 'NN'),\n",
              "  ('first', 'RB'),\n",
              "  ('timep', 'JJ'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('bwzkhhpen', 'NN')],\n",
              " [('ok', 'NN'),\n",
              "  ('first', 'RB'),\n",
              "  ('offici', 'JJ'),\n",
              "  ('patient', 'NN'),\n",
              "  ('confirm', 'NN'),\n",
              "  ('th', 'NN'),\n",
              "  ('decemb', 'NN'),\n",
              "  ('st', 'NN'),\n",
              "  ('decemb', 'NN'),\n",
              "  ('link', 'NN'),\n",
              "  ('wuhan', 'IN'),\n",
              "  ('sea', 'NN'),\n",
              "  ('market', 'NN'),\n",
              "  ('coronarviru', 'NN'),\n",
              "  ('wuhancoronoviru', 'VBP'),\n",
              "  ('ncov', 'JJ'),\n",
              "  ('coronavirusoutbreak', 'NN'),\n",
              "  ('coronaviruschinahttp', 'NN'),\n",
              "  ('www', 'NN'),\n",
              "  ('sciencemag', 'NN'),\n",
              "  ('org', 'JJ'),\n",
              "  ('news', 'NN'),\n",
              "  ('wuhan', 'VBD'),\n",
              "  ('seafood', 'JJ'),\n",
              "  ('market', 'NN'),\n",
              "  ('may', 'MD'),\n",
              "  ('sourc', 'VB'),\n",
              "  ('novel', 'JJ'),\n",
              "  ('viru', 'NNS'),\n",
              "  ('spread', 'VBD'),\n",
              "  ('global', 'JJ')],\n",
              " [('primer', 'NN'),\n",
              "  ('caso', 'NN'),\n",
              "  ('confirmado', 'NN'),\n",
              "  ('en', 'IN'),\n",
              "  ('espa', 'NN'),\n",
              "  ('est', 'JJS'),\n",
              "  ('espa', 'NN'),\n",
              "  ('preparada', 'NN'),\n",
              "  ('para', 'NN'),\n",
              "  ('el', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('m', 'NN'),\n",
              "  ('informaci', 'NN'),\n",
              "  ('n', 'JJ'),\n",
              "  ('http', 'NN'),\n",
              "  ('raroraroraro', 'NN'),\n",
              "  ('github', 'NN'),\n",
              "  ('io', 'NN'),\n",
              "  ('prle', 'NN'),\n",
              "  ('pandemia', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('coronavirusespanap', 'VBP'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('gthdzgxm', 'NN')],\n",
              " [('wuhancoronov', 'NN'),\n",
              "  ('ru', 'NN'),\n",
              "  ('hastal', 'JJ'),\n",
              "  ('km', 'NN'),\n",
              "  ('biyolojik', 'NN'),\n",
              "  ('silahm', 'NN'),\n",
              "  ('who', 'WP'),\n",
              "  ('opinion', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('leak', 'JJ'),\n",
              "  ('weapon', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('www', 'NN'),\n",
              "  ('livemint', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('opinion', 'NN'),\n",
              "  ('quick', 'JJ'),\n",
              "  ('edit', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('leak', 'NN'),\n",
              "  ('weapon', 'NN'),\n",
              "  ('html', 'NN')],\n",
              " [('panik', 'NN'),\n",
              "  ('rman', 'NN'),\n",
              "  ('yor', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('chine', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('slmhktn', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('you', 'PRP'),\n",
              "  ('need', 'VBP'),\n",
              "  ('to', 'TO'),\n",
              "  ('read', 'VB'),\n",
              "  ('thi', 'JJ'),\n",
              "  ('coronaviru', 'NNS'),\n",
              "  ('wuhan', 'VBP'),\n",
              "  ('wuhancoronoviru', 'JJ'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('thesharpedg', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('three', 'CD'),\n",
              "  ('peopl', 'NN'),\n",
              "  ('southern', 'JJ'),\n",
              "  ('germani', 'NN'),\n",
              "  ('contract', 'NN'),\n",
              "  ('coronaviru', 'JJ'),\n",
              "  ('employe', 'NN'),\n",
              "  ('compani', 'NN'),\n",
              "  ('man', 'NN'),\n",
              "  ('becam', 'NN'),\n",
              "  ('first', 'RB'),\n",
              "  ('person', 'NN'),\n",
              "  ('germani', 'JJ'),\n",
              "  ('becom', 'NN'),\n",
              "  ('infect', 'NN'),\n",
              "  ('viru', 'NN'),\n",
              "  ('bavarian', 'JJ'),\n",
              "  ('health', 'NN'),\n",
              "  ('ministri', 'NN'),\n",
              "  ('said', 'VBD'),\n",
              "  ('tuesday', 'JJ'),\n",
              "  ('wuhancoronoviru', 'JJ'),\n",
              "  ('coronavirusp', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('wjccppfsv', 'NN')],\n",
              " [('there', 'RB'),\n",
              "  ('peopl', 'JJ'),\n",
              "  ('suspect', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('faint', 'NN'),\n",
              "  ('suddenli', 'NN'),\n",
              "  ('metro', 'NN'),\n",
              "  ('station', 'NN'),\n",
              "  ('hk', 'VBD'),\n",
              "  ('it', 'PRP'),\n",
              "  ('terribl', 'VBZ'),\n",
              "  ('alreadi', 'NN'),\n",
              "  ('around', 'IN'),\n",
              "  ('us', 'PRP'),\n",
              "  ('you', 'PRP'),\n",
              "  ('never', 'RB'),\n",
              "  ('know', 'VBP'),\n",
              "  ('someon', 'JJ'),\n",
              "  ('fall', 'NN'),\n",
              "  ('next', 'JJ'),\n",
              "  ('pic', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('bjozxnble', 'JJ')],\n",
              " [('hk', 'NN'),\n",
              "  ('strike', 'NN'),\n",
              "  ('along', 'IN'),\n",
              "  ('medic', 'JJ'),\n",
              "  ('staff', 'NN'),\n",
              "  ('savelif', 'NN'),\n",
              "  ('savehongkong', 'JJ'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('coronavirusoutbreak', 'NN'),\n",
              "  ('wuhanoutbreak', 'NN'),\n",
              "  ('soshk', 'NN'),\n",
              "  ('ccp', 'NN'),\n",
              "  ('china', 'VBP'),\n",
              "  ('terrorist', 'JJ'),\n",
              "  ('antichinazi', 'JJ'),\n",
              "  ('antiauthoritanismp', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('ngiaxfay', 'NN')],\n",
              " [('necesito', 'JJ'),\n",
              "  ('que', 'NN'),\n",
              "  ('nicol', 'NN'),\n",
              "  ('haga', 'NN'),\n",
              "  ('una', 'JJ'),\n",
              "  ('visita', 'NN'),\n",
              "  ('ofici', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('hecho', 'NN'),\n",
              "  ('la', 'NN'),\n",
              "  ('vistima', 'FW'),\n",
              "  ('buscando', 'NN'),\n",
              "  ('convenio', 'NN'),\n",
              "  ('eso', 'NN')],\n",
              " [('wuhancoronoviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('goodlast', 'NN'),\n",
              "  ('hope', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('chines', 'NNS'),\n",
              "  ('citizen', 'NNS'),\n",
              "  ('share', 'NN'),\n",
              "  ('method', 'JJ'),\n",
              "  ('cure', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('bring', 'VBG'),\n",
              "  ('garlic', 'JJ'),\n",
              "  ('water', 'NN'),\n",
              "  ('boil', 'NN'),\n",
              "  ('drink', 'VBP'),\n",
              "  ('cup', 'JJ'),\n",
              "  ('day', 'NN'),\n",
              "  ('thi', 'VB'),\n",
              "  ('ordinari', 'JJ'),\n",
              "  ('fakenew', 'NNS'),\n",
              "  ('spread', 'VBP'),\n",
              "  ('around', 'IN'),\n",
              "  ('social', 'JJ'),\n",
              "  ('media', 'NNS'),\n",
              "  ('china', 'VBP'),\n",
              "  ('http', 'JJ'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('kui', 'NN'),\n",
              "  ('yang', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('wuhancoronoviru', 'RB'),\n",
              "  ('new', 'JJ'),\n",
              "  ('threat', 'NN'),\n",
              "  ('it', 'PRP'),\n",
              "  ('extens', 'VBZ'),\n",
              "  ('simmer', 'JJ'),\n",
              "  ('panic', 'NN'),\n",
              "  ('i', 'NN'),\n",
              "  ('experi', 'VBP'),\n",
              "  ('everi', 'JJ'),\n",
              "  ('winter', 'NN'),\n",
              "  ('leav', 'NN'),\n",
              "  ('hous', 'JJ'),\n",
              "  ('prepar', 'NN'),\n",
              "  ('travers', 'NNS'),\n",
              "  ('bio', 'VBP'),\n",
              "  ('toxic', 'JJ'),\n",
              "  ('environ', 'NN')],\n",
              " [('it', 'PRP'),\n",
              "  ('seem', 'VBP'),\n",
              "  ('number', 'NN'),\n",
              "  ('death', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('patient', 'JJ'),\n",
              "  ('china', 'NN'),\n",
              "  ('chang', 'NN'),\n",
              "  ('regularli', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN')],\n",
              " [('para', 'NN'),\n",
              "  ('ficar', 'NN'),\n",
              "  ('de', 'IN'),\n",
              "  ('aviso', 'FW'),\n",
              "  ('ao', 'JJ'),\n",
              "  ('maluco', 'NN'),\n",
              "  ('que', 'NN'),\n",
              "  ('ficaram', 'NN'),\n",
              "  ('inventando', 'NN'),\n",
              "  ('n', 'JJ'),\n",
              "  ('mero', 'NN'),\n",
              "  ('de', 'IN'),\n",
              "  ('infectado', 'FW'),\n",
              "  ('e', 'FW'),\n",
              "  ('morto', 'FW'),\n",
              "  ('ela', 'FW'),\n",
              "  ('n', 'FW'),\n",
              "  ('tem', 'NN'),\n",
              "  ('freio', 'JJ'),\n",
              "  ('autom', 'NN'),\n",
              "  ('tico', 'NN'),\n",
              "  ('n', 'JJ'),\n",
              "  ('ter', 'NN'),\n",
              "  ('que', 'NN'),\n",
              "  ('ser', 'NN'),\n",
              "  ('contida', 'NN'),\n",
              "  ('descartem', 'NN'),\n",
              "  ('essa', 'JJ'),\n",
              "  ('lorota', 'NN'),\n",
              "  ('de', 'IN'),\n",
              "  ('que', 'FW'),\n",
              "  ('se', 'FW'),\n",
              "  ('deixar', 'FW'),\n",
              "  ('ela', 'FW'),\n",
              "  ('perd', 'FW'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('coronarviru', 'NN'),\n",
              "  ('coronaoutbreak', 'NN'),\n",
              "  ('brasil', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('pic', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('deltejabh', 'NN')],\n",
              " [('we', 'PRP'),\n",
              "  ('realli', 'VBP'),\n",
              "  ('gon', 'VBG'),\n",
              "  ('na', 'TO'),\n",
              "  ('trust', 'VB'),\n",
              "  ('california', 'NN'),\n",
              "  ('quarantin', 'JJ'),\n",
              "  ('american', 'JJ'),\n",
              "  ('fli', 'NN'),\n",
              "  ('america', 'NN'),\n",
              "  ('possibl', 'NN'),\n",
              "  ('w', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('ca', 'MD'),\n",
              "  ('even', 'RB'),\n",
              "  ('keep', 'VB'),\n",
              "  ('mexican', 'JJ'),\n",
              "  ('china', 'NN'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('wuhanviru', 'NN')],\n",
              " [('can', 'MD'),\n",
              "  ('cdcgov', 'VB'),\n",
              "  ('travelgov', 'JJ'),\n",
              "  ('pleas', 'NNS'),\n",
              "  ('explain', 'VBP'),\n",
              "  ('usa', 'JJ'),\n",
              "  ('accept', 'IN'),\n",
              "  ('plane', 'NN'),\n",
              "  ('willingli', 'NN'),\n",
              "  ('ground', 'NN'),\n",
              "  ('zero', 'CD'),\n",
              "  ('locat', 'NN'),\n",
              "  ('rapidli', 'NN'),\n",
              "  ('spread', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('kill', 'VB'),\n",
              "  ('sever', 'JJ'),\n",
              "  ('peopl', 'NN'),\n",
              "  ('hospit', 'NN'),\n",
              "  ('mani', 'NN'),\n",
              "  ('wuhanoutbreak', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('wuhanchinahttp', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'VBP'),\n",
              "  ('livecrisisnew', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('your', 'PRP$'),\n",
              "  ('job', 'NN'),\n",
              "  ('super', 'JJ'),\n",
              "  ('high', 'JJ'),\n",
              "  ('risk', 'NN'),\n",
              "  ('never', 'RB'),\n",
              "  ('work', 'NN'),\n",
              "  ('without', 'IN'),\n",
              "  ('mask', 'NN'),\n",
              "  ('goggl', 'NN'),\n",
              "  ('rmb', 'NN'),\n",
              "  ('viru', 'NN'),\n",
              "  ('could', 'MD'),\n",
              "  ('notic', 'VB'),\n",
              "  ('symptom', 'VB'),\n",
              "  ('even', 'RB'),\n",
              "  ('fever', 'WRB'),\n",
              "  ('wuhancoronoviru', 'NN')],\n",
              " [('the', 'DT'),\n",
              "  ('ppl', 'NN'),\n",
              "  ('thread', 'NN'),\n",
              "  ('said', 'VBD'),\n",
              "  ('mask', 'JJ'),\n",
              "  ('work', 'NN'),\n",
              "  ('ridicul', 'NN'),\n",
              "  ('ye', 'PRP'),\n",
              "  ('mask', 'VBZ'),\n",
              "  ('the', 'DT'),\n",
              "  ('best', 'JJS'),\n",
              "  ('way', 'NN'),\n",
              "  ('stop', 'NN'),\n",
              "  ('u', 'NN'),\n",
              "  ('catch', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('wash', 'NN'),\n",
              "  ('hand', 'NN'),\n",
              "  ('help', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('apriloa', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('wuhancoronoviru', 'NN'),\n",
              "  ('pic', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('foaspocwr', 'NN')],\n",
              " [('addawordruinabook', 'NN'),\n",
              "  ('wuhan', 'WP'),\n",
              "  ('anim', 'VBZ'),\n",
              "  ('farm', 'NN'),\n",
              "  ('fallontonight', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('pic', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('ufmdssro', 'NN')],\n",
              " [('almost', 'RB'),\n",
              "  ('hong', 'JJ'),\n",
              "  ('kong', 'JJ'),\n",
              "  ('patient', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('come', 'VBN'),\n",
              "  ('mainland', 'NN'),\n",
              "  ('they', 'PRP'),\n",
              "  ('hongkong', 'VBP'),\n",
              "  ('they', 'PRP'),\n",
              "  ('peopl', 'VBP'),\n",
              "  ('come', 'VB'),\n",
              "  ('infect', 'JJ'),\n",
              "  ('us', 'PRP'),\n",
              "  ('there', 'EX'),\n",
              "  ('reason', 'NN'),\n",
              "  ('nurs', 'NNS'),\n",
              "  ('risk', 'VBP'),\n",
              "  ('life', 'NN'),\n",
              "  ('serv', 'JJ'),\n",
              "  ('china', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('cnni', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('coronaviru', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('http', 'VBD'),\n",
              "  ('moneymaven', 'RB'),\n",
              "  ('io', 'JJ'),\n",
              "  ('mishtalk', 'NN'),\n",
              "  ('econom', 'NN'),\n",
              "  ('hundr', 'NN'),\n",
              "  ('viru', 'NN'),\n",
              "  ('carri', 'NN'),\n",
              "  ('plane', 'NN'),\n",
              "  ('head', 'VBP'),\n",
              "  ('us', 'PRP'),\n",
              "  ('london', 'JJ'),\n",
              "  ('pari', 'JJ'),\n",
              "  ('vancouv', 'NN'),\n",
              "  ('ejnxiubmhk', 'NN'),\n",
              "  ('cunpwjclna', 'NN')],\n",
              " [('esto', 'JJ'),\n",
              "  ('tien', 'NN'),\n",
              "  ('que', 'NN'),\n",
              "  ('ser', 'VBD'),\n",
              "  ('co', 'JJ'),\n",
              "  ('el', 'JJ'),\n",
              "  ('equipo', 'NN'),\n",
              "  ('de', 'IN'),\n",
              "  ('f', 'FW'),\n",
              "  ('tbol', 'NN'),\n",
              "  ('de', 'IN'),\n",
              "  ('wuhancoronoviru', 'FW'),\n",
              "  ('llegar', 'FW'),\n",
              "  ('ana', 'FW'),\n",
              "  ('m', 'FW'),\n",
              "  ('laga', 'FW'),\n",
              "  ('hacer', 'NN'),\n",
              "  ('la', 'FW'),\n",
              "  ('pretemporada', 'FW'),\n",
              "  ('http', 'NN'),\n",
              "  ('www', 'NN'),\n",
              "  ('elmundo', 'NN'),\n",
              "  ('es', 'NN'),\n",
              "  ('deport', 'NN'),\n",
              "  ('futbol', 'NN'),\n",
              "  ('edcfccafbcf', 'NN'),\n",
              "  ('html', 'NN')],\n",
              " [('mr', 'NN'),\n",
              "  ('diy', 'NN'),\n",
              "  ('hand', 'NN'),\n",
              "  ('million', 'CD'),\n",
              "  ('mask', 'NN'),\n",
              "  ('free', 'JJ'),\n",
              "  ('combat', 'NN'),\n",
              "  ('viru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('www', 'NN'),\n",
              "  ('thestar', 'NN'),\n",
              "  ('com', 'JJ'),\n",
              "  ('news', 'NN'),\n",
              "  ('nation', 'NN'),\n",
              "  ('mr', 'NN'),\n",
              "  ('diy', 'NN'),\n",
              "  ('hand', 'NN'),\n",
              "  ('million', 'CD'),\n",
              "  ('mask', 'NN'),\n",
              "  ('free', 'JJ'),\n",
              "  ('combat', 'NN'),\n",
              "  ('viru', 'NN'),\n",
              "  ('xjyfqgv', 'NNP'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('thank', 'NN'),\n",
              "  ('mr', 'NN'),\n",
              "  ('diy', 'NN'),\n",
              "  ('salut', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('wuhanoutbreak', 'NN'),\n",
              "  ('wuhan', 'NN')],\n",
              " [('the', 'DT'),\n",
              "  ('continu', 'NN'),\n",
              "  ('open', 'JJ'),\n",
              "  ('border', 'NN'),\n",
              "  ('like', 'IN'),\n",
              "  ('airport', 'NN'),\n",
              "  ('mean', 'VBP'),\n",
              "  ('influx', 'NN'),\n",
              "  ('probabl', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('carrier', 'NN'),\n",
              "  ('hk', 'NN'),\n",
              "  ('thi', 'NN'),\n",
              "  ('put', 'VBD'),\n",
              "  ('hker', 'JJR'),\n",
              "  ('matter', 'NN'),\n",
              "  ('polit', 'NN'),\n",
              "  ('spectrum', 'RB'),\n",
              "  ('high', 'JJ'),\n",
              "  ('risk', 'NN'),\n",
              "  ('the', 'DT'),\n",
              "  ('medic', 'NN'),\n",
              "  ('sector', 'NN'),\n",
              "  ('face', 'NN'),\n",
              "  ('unbear', 'JJ'),\n",
              "  ('pressur', 'NN'),\n",
              "  ('collaps', 'NNS'),\n",
              "  ('hker', 'NN'),\n",
              "  ('suffer', 'NN')],\n",
              " [('we', 'PRP'),\n",
              "  ('live', 'VBP'),\n",
              "  ('china', 'JJ'),\n",
              "  ('lie', 'NN'),\n",
              "  ('wuhan', 'JJ'),\n",
              "  ('ist', 'NN'),\n",
              "  ('like', 'IN'),\n",
              "  ('hell', 'NN'),\n",
              "  ('more', 'RBR'),\n",
              "  ('peopl', 'JJ'),\n",
              "  ('die', 'NN'),\n",
              "  ('liwenliang', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('lie', 'NN'),\n",
              "  ('help', 'NN'),\n",
              "  ('so', 'RB'),\n",
              "  ('wuhan', 'JJ'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('wangzhian', 'JJ'),\n",
              "  ('statu', 'NN')],\n",
              " [('wuhancoronoviru', 'NN'),\n",
              "  ('chinaoutbreak', 'NN'),\n",
              "  ('virus', 'NN'),\n",
              "  ('fact', 'NN'),\n",
              "  ('pic', 'IN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('mlnsriocp', 'NN')],\n",
              " [('corona', 'NN'),\n",
              "  ('viru', 'NN'),\n",
              "  ('critic', 'JJ'),\n",
              "  ('updat', 'JJ'),\n",
              "  ('misheldbyt', 'NN'),\n",
              "  ('deceptionbyt', 'NN'),\n",
              "  ('qanon', 'NN'),\n",
              "  ('qarmi', 'JJ'),\n",
              "  ('panicinchina', 'NN'),\n",
              "  ('wearethenewsnow', 'VBP'),\n",
              "  ('qnew', 'RB'),\n",
              "  ('coronaviru', 'JJ'),\n",
              "  ('q', 'NN'),\n",
              "  ('wwgwga', 'NN'),\n",
              "  ('wuhanoutbreak', 'NN'),\n",
              "  ('coronavirusoutbreak', 'NN'),\n",
              "  ('quarantin', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('seektruthcuzdeceptionbyt', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('youtu', 'NN'),\n",
              "  ('xobeazfivg', 'NNP'),\n",
              "  ('via', 'IN'),\n",
              "  ('youtub', 'NN')],\n",
              " [('wuhanviru', 'NN'), ('wuhancoronoviru', 'NN'), ('wuflu', 'NN')],\n",
              " [('respect', 'NN'),\n",
              "  ('be', 'VB'),\n",
              "  ('honest', 'JJ'),\n",
              "  ('easi', 'JJ'),\n",
              "  ('china', 'NN'),\n",
              "  ('wuhancoronoviru', 'IN'),\n",
              "  ('china', 'NN'),\n",
              "  ('soshk', 'NN')],\n",
              " [('chines', 'NNS'),\n",
              "  ('doctor', 'NN'),\n",
              "  ('li', 'NN'),\n",
              "  ('wenliang', 'NN'),\n",
              "  ('wuhan', 'VBD'),\n",
              "  ('whistleblow', 'WP'),\n",
              "  ('ill', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('februari', 'JJ'),\n",
              "  ('zacharykhubbard', 'NN'),\n",
              "  ('gematria', 'NN'),\n",
              "  ('broadcast', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('youtu', 'NN'),\n",
              "  ('zsoq', 'NN'),\n",
              "  ('vg', 'NN'),\n",
              "  ('wuhanoutbreak', 'NN'),\n",
              "  ('coronavirustruth', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('chinaviru', 'NN'),\n",
              "  ('coronaviruschalleng', 'NN'),\n",
              "  ('chinawuhan', 'NN')],\n",
              " [('rip', 'NN'),\n",
              "  ('dr', 'NN'),\n",
              "  ('li', 'NN'),\n",
              "  ('wen', 'NN'),\n",
              "  ('liang', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN')],\n",
              " [('new', 'JJ'),\n",
              "  ('video', 'NN'),\n",
              "  ('caus', 'NN'),\n",
              "  ('spread', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('youtu', 'NN'),\n",
              "  ('zngvaggqdw', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('corona', 'VBP'),\n",
              "  ('viru', 'JJ'),\n",
              "  ('health', 'NN'),\n",
              "  ('china', 'NN'),\n",
              "  ('chinaviru', 'NN'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('pic', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('caabyjt', 'NN')],\n",
              " [('ff', 'NN'),\n",
              "  ('wuhanpneumonia', 'NN'),\n",
              "  ('wuhan', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN')],\n",
              " [('do', 'VB'),\n",
              "  ('look', 'NNS'),\n",
              "  ('like', 'IN'),\n",
              "  ('joke', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('vanessa', 'NN'),\n",
              "  ('zhanguk', 'NN'),\n",
              "  ('statu', 'NN')],\n",
              " [('calendar', 'NN'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('http', 'NN'),\n",
              "  ('en', 'IN'),\n",
              "  ('ncov', 'JJ'),\n",
              "  ('su', 'NN'),\n",
              "  ('see', 'VBP'),\n",
              "  ('trash', 'JJ'),\n",
              "  ('coronaviru', 'NN'),\n",
              "  ('wuhancoronoviru', 'NN'),\n",
              "  ('ncov', 'JJ'),\n",
              "  ('ncov', 'JJ'),\n",
              "  ('wuhanpnemoniap', 'NN'),\n",
              "  ('twitter', 'NN'),\n",
              "  ('com', 'NN'),\n",
              "  ('zvygcomc', 'NN')]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cZNYOcHmRA7",
        "colab_type": "code",
        "outputId": "e5e541f7-3c52-4851-ca4a-39b11d2f8569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "pip install stanfordnlp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stanfordnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/bf/5d2898febb6e993fcccd90484cba3c46353658511a41430012e901824e94/stanfordnlp-0.2.0-py3-none-any.whl (158kB)\n",
            "\r\u001b[K     |██                              | 10kB 21.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 40kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (4.28.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (3.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (1.17.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanfordnlp) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanfordnlp) (45.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (1.24.3)\n",
            "Installing collected packages: stanfordnlp\n",
            "Successfully installed stanfordnlp-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLWwnCEMaVgB",
        "colab_type": "code",
        "outputId": "5aa5c7c3-6d1f-4752-c485-85a5ec19d832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Dependency Parsing, Constituency Parsing\n",
        "\n",
        "import stanfordnlp\n",
        "stanfordnlp.download('en')\n",
        "\n",
        "nlp = stanfordnlp.Pipeline()\n",
        "for i in lemmatizedWords:\n",
        "  sentence = i\n",
        "  #doc = nlp(sentence)\n",
        "  doc.sentences[0].print_dependencies()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using the default treebank \"en_ewt\" for language \"en\".\n",
            "Would you like to download the models for: en_ewt now? (Y/n)\n",
            "y\n",
            "\n",
            "Default download directory: /root/stanfordnlp_resources\n",
            "Hit enter to continue or type an alternate directory.\n",
            "\n",
            "\n",
            "Downloading models for: en_ewt\n",
            "Download location: /root/stanfordnlp_resources/en_ewt_models.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 235M/235M [00:17<00:00, 12.7MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Download complete.  Models saved to: /root/stanfordnlp_resources/en_ewt_models.zip\n",
            "Extracting models file for: en_ewt\n",
            "Cleaning up...Done.\n",
            "Use device: cpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "---\n",
            "Loading: pos\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "---\n",
            "Loading: lemma\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Building an attentional Seq2Seq model...\n",
            "Using a Bi-LSTM encoder\n",
            "Using soft attention for LSTM.\n",
            "Finetune all embeddings.\n",
            "[Running seq2seq lemmatizer with edit classifier]\n",
            "---\n",
            "Loading: depparse\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n",
            "('covid', '3', 'amod')\n",
            "('wuhancoronoviru', '3', 'amod')\n",
            "('pleas', '4', 'nsubj')\n",
            "('stop', '0', 'root')\n",
            "('use', '4', 'ccomp')\n",
            "('abbrevi', '7', 'compound')\n",
            "('cover', '10', 'compound')\n",
            "('ccp', '10', 'compound')\n",
            "('crime', '10', 'compound')\n",
            "('http', '14', 'compound')\n",
            "('twitter', '14', 'compound')\n",
            "('com', '14', 'compound')\n",
            "('liuyun', '14', 'compound')\n",
            "('statu', '5', 'obj')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFN2QbMPqKfq",
        "colab_type": "code",
        "outputId": "57108c5a-640a-42b1-f082-1540a9b8f893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        }
      },
      "source": [
        "#3.2 \n",
        "#Dependency\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en\")\n",
        "sentence = lemmatizedWords[99]\n",
        "doc = nlp(sentence)\n",
        "# doc = nlp(u'The team is not performing well in the match')\n",
        "\n",
        "for token in doc:\n",
        "    print (str(token.text),  str(token.lemma_),  str(token.pos_),  str(token.dep_))\n",
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style='dep',jupyter=True,options={'distance': 140})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calendar calendar NOUN compound\n",
            "coronaviru coronaviru NOUN ROOT\n",
            "http http NOUN advmod\n",
            "en en ADP ROOT\n",
            "ncov ncov NOUN compound\n",
            "su su NOUN nsubj\n",
            "see see VERB ROOT\n",
            "trash trash NOUN compound\n",
            "coronaviru coronaviru NOUN compound\n",
            "wuhancoronoviru wuhancoronoviru NOUN dobj\n",
            "ncov ncov NOUN compound\n",
            "ncov ncov ADJ compound\n",
            "wuhanpnemoniap wuhanpnemoniap NOUN amod\n",
            "twitter twitter NOUN nmod\n",
            "com com NOUN compound\n",
            "zvygcomc zvygcomc NOUN appos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a472dfa4ef77427fa73b93384957883a-0\" class=\"displacy\" width=\"2290\" height=\"417.0\" direction=\"ltr\" style=\"max-width: none; height: 417.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">calendar</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"190\">coronaviru</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"190\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"330\">http</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"330\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"470\">en</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"470\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">ncov</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">su</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">see</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1030\">trash</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1030\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1170\">coronaviru</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1170\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1310\">wuhancoronoviru</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1310\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">ncov</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1590\">ncov</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1590\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1730\">wuhanpnemoniap</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1730\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1870\">twitter</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1870\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2010\">com</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2010\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"327.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">zvygcomc</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a472dfa4ef77427fa73b93384957883a-0-0\" stroke-width=\"2px\" d=\"M70,282.0 C70,212.0 175.0,212.0 175.0,282.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a472dfa4ef77427fa73b93384957883a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,284.0 L62,272.0 78,272.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a472dfa4ef77427fa73b93384957883a-0-1\" stroke-width=\"2px\" d=\"M210,282.0 C210,212.0 315.0,212.0 315.0,282.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a472dfa4ef77427fa73b93384957883a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M315.0,284.0 L323.0,272.0 307.0,272.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a472dfa4ef77427fa73b93384957883a-0-2\" stroke-width=\"2px\" d=\"M630,282.0 C630,212.0 735.0,212.0 735.0,282.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a472dfa4ef77427fa73b93384957883a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M630,284.0 L622,272.0 638,272.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a472dfa4ef77427fa73b93384957883a-0-3\" stroke-width=\"2px\" d=\"M770,282.0 C770,212.0 875.0,212.0 875.0,282.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a472dfa4ef77427fa73b93384957883a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,284.0 L762,272.0 778,272.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a472dfa4ef77427fa73b93384957883a-0-4\" stroke-width=\"2px\" d=\"M1050,282.0 C1050,142.0 1300.0,142.0 1300.0,282.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a472dfa4ef77427fa73b93384957883a-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1050,284.0 L1042,272.0 1058,272.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a472dfa4ef77427fa73b93384957883a-0-5\" stroke-width=\"2px\" d=\"M1190,282.0 C1190,212.0 1295.0,212.0 1295.0,282.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a472dfa4ef77427fa73b93384957883a-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1190,284.0 L1182,272.0 1198,272.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a472dfa4ef77427fa73b93384957883a-0-6\" stroke-width=\"2px\" d=\"M910,282.0 C910,72.0 1305.0,72.0 1305.0,282.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a472dfa4ef77427fa73b93384957883a-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1305.0,284.0 L1313.0,272.0 1297.0,272.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a472dfa4ef77427fa73b93384957883a-0-7\" stroke-width=\"2px\" d=\"M1470,282.0 C1470,212.0 1575.0,212.0 1575.0,282.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a472dfa4ef77427fa73b93384957883a-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1470,284.0 L1462,272.0 1478,272.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a472dfa4ef77427fa73b93384957883a-0-8\" stroke-width=\"2px\" d=\"M1610,282.0 C1610,212.0 1715.0,212.0 1715.0,282.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a472dfa4ef77427fa73b93384957883a-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1610,284.0 L1602,272.0 1618,272.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a472dfa4ef77427fa73b93384957883a-0-9\" stroke-width=\"2px\" d=\"M1750,282.0 C1750,72.0 2145.0,72.0 2145.0,282.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a472dfa4ef77427fa73b93384957883a-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1750,284.0 L1742,272.0 1758,272.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a472dfa4ef77427fa73b93384957883a-0-10\" stroke-width=\"2px\" d=\"M1890,282.0 C1890,142.0 2140.0,142.0 2140.0,282.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a472dfa4ef77427fa73b93384957883a-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1890,284.0 L1882,272.0 1898,272.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a472dfa4ef77427fa73b93384957883a-0-11\" stroke-width=\"2px\" d=\"M2030,282.0 C2030,212.0 2135.0,212.0 2135.0,282.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a472dfa4ef77427fa73b93384957883a-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2030,284.0 L2022,272.0 2038,272.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a472dfa4ef77427fa73b93384957883a-0-12\" stroke-width=\"2px\" d=\"M1330,282.0 C1330,2.0 2150.0,2.0 2150.0,282.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a472dfa4ef77427fa73b93384957883a-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2150.0,284.0 L2158.0,272.0 2142.0,272.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gfIMDTIb-Uu",
        "colab_type": "code",
        "outputId": "8a8e3a55-a52e-42be-c92a-ca7b5dcb770e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "!pip install cython numpy\n",
        "!pip install benepar[cpu]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.5)\n",
            "Collecting benepar[cpu]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/7b/6cd9c60e1613a5ad388b4f883fa2aeaddcd8a7ad0a8d5ed87e0d23f159d8/benepar-0.1.2.tar.gz (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from benepar[cpu]) (0.29.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from benepar[cpu]) (1.17.5)\n",
            "Requirement already satisfied: nltk>=3.2 in /usr/local/lib/python3.6/dist-packages (from benepar[cpu]) (3.2.5)\n",
            "Requirement already satisfied: tensorflow>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from benepar[cpu]) (1.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.2->benepar[cpu]) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.11.0->benepar[cpu]) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.11.0->benepar[cpu]) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.11.0->benepar[cpu]) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.11.0->benepar[cpu]) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.11.0->benepar[cpu]) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.11.0->benepar[cpu]) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.11.0->benepar[cpu]) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.11.0->benepar[cpu]) (0.34.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.11.0->benepar[cpu]) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.11.0->benepar[cpu]) (1.15.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.11.0->benepar[cpu]) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.11.0->benepar[cpu]) (1.11.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.11.0->benepar[cpu]) (0.1.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.11.0->benepar[cpu]) (1.27.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=1.11.0->benepar[cpu]) (2.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.11.0->benepar[cpu]) (45.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.11.0->benepar[cpu]) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.11.0->benepar[cpu]) (1.0.0)\n",
            "Building wheels for collected packages: benepar\n",
            "  Building wheel for benepar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for benepar: filename=benepar-0.1.2-cp36-cp36m-linux_x86_64.whl size=106713 sha256=f19a089f754dc96343b72cf64dcc0a4dbfef5cf64d37395e00983bcdc01b8ba1\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/f5/06/d88543b19a9b326007d7538298a139e994b1d2eecb003bf5af\n",
            "Successfully built benepar\n",
            "Installing collected packages: benepar\n",
            "Successfully installed benepar-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiBilslDcxTA",
        "colab_type": "code",
        "outputId": "a5fcf0ba-bcc7-4ae4-dccb-7da501e1490e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BwLxBY6fMiV",
        "colab_type": "code",
        "outputId": "82c0bf41-1777-4cd2-f583-768bd41da98b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        }
      },
      "source": [
        "import benepar\n",
        "benepar.download('benepar_en2')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package benepar_en2 to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Jt8JP8g2Pr",
        "colab_type": "code",
        "outputId": "e0e12a70-cc42-47e9-d3c9-872f6e05325c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "#3.2 Constituenccy parsing with a sample tweet\n",
        "\n",
        "import benepar\n",
        "parser = benepar.Parser(\"benepar_en2\")\n",
        "tree = parser.parse(\"China takes steps to control corona virus.\")\n",
        "print(tree)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  (NP (NNP China))\n",
            "  (VP\n",
            "    (VBZ takes)\n",
            "    (NP (NNS steps))\n",
            "    (S (VP (TO to) (VP (VB control) (NP (NNP corona) (NN virus))))))\n",
            "  (. .))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pnxmW5SIBQX",
        "colab_type": "code",
        "outputId": "ef957af9-6895-4cc8-b392-b0eb789ed6c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#3.3 Named Entity Recognition\n",
        "import spacy \n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "count=0 \n",
        "for i in lemmatizedWords:\n",
        "  count+=1\n",
        "  print('Sentence Number-',count)\n",
        "  sentence = i\n",
        "  doc = nlp(sentence)\n",
        "  for ent in doc.ents:\n",
        "    print(ent.text, ent.label_) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence Number- 1\n",
            "Sentence Number- 2\n",
            "Sentence Number- 3\n",
            "Sentence Number- 4\n",
            "Sentence Number- 5\n",
            "Sentence Number- 6\n",
            "Sentence Number- 7\n",
            "Sentence Number- 8\n",
            "Sentence Number- 9\n",
            "Sentence Number- 10\n",
            "Sentence Number- 11\n",
            "Sentence Number- 12\n",
            "Sentence Number- 13\n",
            "Sentence Number- 14\n",
            "first ORDINAL\n",
            "Sentence Number- 15\n",
            "Sentence Number- 16\n",
            "Sentence Number- 17\n",
            "Sentence Number- 18\n",
            "Sentence Number- 19\n",
            "Sentence Number- 20\n",
            "Sentence Number- 21\n",
            "Sentence Number- 22\n",
            "Sentence Number- 23\n",
            "Sentence Number- 24\n",
            "Sentence Number- 25\n",
            "Sentence Number- 26\n",
            "Sentence Number- 27\n",
            "Sentence Number- 28\n",
            "Sentence Number- 29\n",
            "Sentence Number- 30\n",
            "Sentence Number- 31\n",
            "Sentence Number- 32\n",
            "Sentence Number- 33\n",
            "Sentence Number- 34\n",
            "Sentence Number- 35\n",
            "Sentence Number- 36\n",
            "Sentence Number- 37\n",
            "Sentence Number- 38\n",
            "Sentence Number- 39\n",
            "Sentence Number- 40\n",
            "Sentence Number- 41\n",
            "today DATE\n",
            "Sentence Number- 42\n",
            "Sentence Number- 43\n",
            "Sentence Number- 44\n",
            "spring DATE\n",
            "one CARDINAL\n",
            "Sentence Number- 45\n",
            "Sentence Number- 46\n",
            "Sentence Number- 47\n",
            "Sentence Number- 48\n",
            "Sentence Number- 49\n",
            "Sentence Number- 50\n",
            "Sentence Number- 51\n",
            "Sentence Number- 52\n",
            "Sentence Number- 53\n",
            "Sentence Number- 54\n",
            "Sentence Number- 55\n",
            "Sentence Number- 56\n",
            "Sentence Number- 57\n",
            "Sentence Number- 58\n",
            "ncov DATE\n",
            "Sentence Number- 59\n",
            "Sentence Number- 60\n",
            "Sentence Number- 61\n",
            "Sentence Number- 62\n",
            "Sentence Number- 63\n",
            "Sentence Number- 64\n",
            "first ORDINAL\n",
            "Sentence Number- 65\n",
            "first ORDINAL\n",
            "Sentence Number- 66\n",
            "Sentence Number- 67\n",
            "Sentence Number- 68\n",
            "Sentence Number- 69\n",
            "Sentence Number- 70\n",
            "three CARDINAL\n",
            "first ORDINAL\n",
            "tuesday DATE\n",
            "Sentence Number- 71\n",
            "Sentence Number- 72\n",
            "Sentence Number- 73\n",
            "Sentence Number- 74\n",
            "Sentence Number- 75\n",
            "day DATE\n",
            "Sentence Number- 76\n",
            "winter DATE\n",
            "Sentence Number- 77\n",
            "Sentence Number- 78\n",
            "Sentence Number- 79\n",
            "Sentence Number- 80\n",
            "zero CARDINAL\n",
            "Sentence Number- 81\n",
            "Sentence Number- 82\n",
            "Sentence Number- 83\n",
            "Sentence Number- 84\n",
            "Sentence Number- 85\n",
            "Sentence Number- 86\n",
            "Sentence Number- 87\n",
            "Sentence Number- 88\n",
            "million CARDINAL\n",
            "million CARDINAL\n",
            "Sentence Number- 89\n",
            "Sentence Number- 90\n",
            "Sentence Number- 91\n",
            "Sentence Number- 92\n",
            "Sentence Number- 93\n",
            "Sentence Number- 94\n",
            "Sentence Number- 95\n",
            "Sentence Number- 96\n",
            "Sentence Number- 97\n",
            "Sentence Number- 98\n",
            "Sentence Number- 99\n",
            "Sentence Number- 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWOtvT2rHNWy",
        "colab_type": "text"
      },
      "source": [
        "**Write your explanations of the constituency parsing tree and dependency parsing tree here (Question 3-2):** "
      ]
    }
  ]
}